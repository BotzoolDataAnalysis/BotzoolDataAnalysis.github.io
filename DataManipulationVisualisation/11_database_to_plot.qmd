---
title: "11 From a database to a plot"
format: html
author: Irena Axmanová
---

Aim of this tutorial is to repeat what we have learned so far. We will step by step show you how to import the data from a database to R, prepare it for further analyses and prepare some basic summary of the data and plot answers to our questions. At the end of this chapter, you will find the final exercises that we want you to do and hand in. The script will be than considered as your final project of this course.

## 11.1 Example of database format data / Turboveg

Turboveg for Windows is a program designed for the storage, selection, and export of vegetation plot data (relevés).The information is divided among several files that are matched by either species ID or releve ID. Within the Turboveg interface, you do not see this structure directly, but you can find it if you look in the *Turbowin* folder, subfolder *data* and particular database (see example below).

![](images/clipboard-4016531900.png)

At some point you need to export the data and process them further. To get Turboveg data to R, you first need to **export the Turboveg database** to a folder where you want to process the data. This step requires **selection of all the plots** you want to export. Alternatively you can access the files directly in the main file in Turbowin, but just to warn you, if you do something wrong here, you might completely loose your data.

## 11.2 Load libraries

```{r}
#| warning: false
library(tidyverse) 
library(readxl)    
library(janitor)  
```

## 11.3 Import env file = headers

One option is to check the exported database manually, open the file called *tvhabita.dbf* in Excel and save it as *tvhabita.xlsx* or *tvhabita.csv* (UTF 8 encoded) file into your *data* folder. Although it includes one more step outside R, it is still rather straightforward and it saves you troubles with different formats in Turboveg and in R (encoding issues). Other option is to open the dbf files directly, for example with the `foreign` package.

You can then import the file as csv file

```{r}
env <- read_csv("data/turboveg_to_R/tvhabita.csv")
```

If you check the imported names, they are rather difficult to handle.

```{r}
names(env)
```

Therefore we will directly change them to tidy names with the `clean_names` function from package `janitor`. Alternative is to rename one by one using e.g. `rename`, but here we want to save time and effort.

```{r}
env <- read_csv("data/turboveg_to_R/tvhabita.csv")%>% 
  clean_names() 

tibble(env)
```

```{r}
names(env)
```

I will prepare a selection of the variables I want to keep and rewrite the file. Always keep releve_nr and coverscale, as you will need them later on.

```{r}
env <- env %>% 
  select(releve_nr, coverscale,field_nr, country, author, date, syntaxon, 
         altitude, exposition, inclinatio, 
         cov_trees, cov_shrubs, cov_herbs, cov_mosses, 
         latitude, longitude, precision, bias_min, bias_gps, locality )
```

Or I can add all the steps I did so far into one pipeline and check the resulting dataset

```{r}
env <- read_csv("data/turboveg_to_R/tvhabita.csv")%>% 
  clean_names() %>% 
  select(releve_nr, coverscale, field_nr, country, author, date, syntaxon,
         altitude, exposition, inclinatio,
         cov_trees, cov_shrubs, cov_herbs, cov_mosses,
         latitude, longitude, precision, bias_min, bias_gps, locality ) %>%
  glimpse()
```

And save it for easier access.

```{r}

write.csv(env, "data/turboveg_to_R/env.csv")
```

## 11.4 Import spe file = species file in a long format

Again, we will open the *tvabund.dbf* in Excel and save it as *tvabund.csv*. And import it to our environment in R. Again, I will use the clean_names function during import, so that we have the same style of the variable names.

```{r}
tvabund <- read_csv("data/turboveg_to_R/tvabund.csv") %>% 
  clean_names()
```

```{r}
glimpse(tvabund)
```

Now we will check the data again and we see, that there are no species names, just numbers. Also the cover is given in the original codes and not in percentages. See the scheme below to understand where each piece of the information is stored.

![](images/clipboard-3501705845.png)

We have to prepare these different files we need, import them and merge them.

### 11.4.1 Nomenclature

In the abund file, species numbers refer to the codes in the checklist used in the Turboveg database. To translate them into species names you will need a translation table with the original number in the database, original name in the database and the name you want to use in the analyses.

We will now import the nomenclature file that is already adapted for Czech flora.

```{r}
nomenclature <- read_csv("data/turboveg_to_R/nomenclature_20251108.csv") %>%
  clean_names()  

tibble(nomenclature)
```

There are several advantages about this approach. First, you can adjust the nomenclature to the newest source/regional checklist etc. In our example the name in Turboveg is translated to the nomenclature presented in the recent Key of the Czech Flora, and it is named after the main editor Kaplan.

Second, I can add a concept that groups several taxa into higher units, e.g. taxa that are not easy to recognise in the field are assigned into aggregates. This is exactly the same approach as you do when you create an expert system file. Here it is even more easy to understand and much easier to change the translation when you need to fix something. The name in this file is called ESy.

Last but not least. I can directly add much more information into such table. For example status, growth form or anything else. Here we have indication if the species is nonvascular.

I might want to check how the species are translated with the use of my translation file and select just these matching rows. Either create a variable called selection indicating if the species is in the subset or not

```{r}
nomenclature_check<- nomenclature %>% 
  left_join(tvabund %>% 
              distinct(species_nr)%>%
              mutate(selection=1)) 
```

or I can even add the frequency, how many times it appears in the records of the dataset

```{r}
nomenclature_check<- nomenclature %>% 
  left_join(tvabund %>% 
              count(species_nr)) 
```

I can then write the file, make adjustments e.g. in Excel and upload it newly. Great thing is that I have indication of which species are in the dataset and I do not have to pay attention to the other rows.

```{r}
#| eval: false
write.csv(nomenclature_check, "data/turboveg_to_R/nomenclature_check.csv")
```

upload the new, adjusted file

```{r}
#| eval: false
nomenclature <- read_csv("data/turboveg_to_R/nomenclature_check.csv") %>%
  clean_names()  
```

### 11.4.2 Cover

We have translation table for nomenclature, but we still need to translate cover codes to percentages. For cover translation we need to use information about cover scale (stored in the header data / tvhabita / env file) and information how to translate the values in that particular scale to percentages. The file here was prepared based on the translation of cover values in different scales to percentages following the EVA database approach. One more column was added to enable different adjustments, for example change the values for rare species etc. For any project I suggest to open the file and check if the scales you are using are there and if you agree with the translation.

```{r}
cover <- read_csv("data/turboveg_to_R/cover_20230402.csv") %>% clean_names()  

tibble(cover)
```

The file here was prepared based on the translation of cover values in different scales to percentages following the EVA database approach. One more column was added to enable different adjustments, for example change the values for rare species etc. For any project I suggest to open the file and check if the scales you are using are there and if you agree with the translation.

Here I can check the different scale names included in the file

```{r}
cover %>% distinct(cover_scale_name) 
```

And I can also filter the rows of the specified scales. E.g. here I am looking for all those that start with a specific pattern "Braun"

```{r}
cover %>% 
  filter(str_starts(cover_scale_name, "Braun")) %>% 
  print(n=20)
```

### 11.4.3 Merging all files together into complete spe file

Finally, I have translation to nomenclature, to cover, so I need to put everything together.

```{r}
tvabund %>% 
  left_join(nomenclature %>% 
              select(species_nr, kaplan, expert_system, nonvascular)) %>% 
  left_join(env %>% select(releve_nr, coverscale)) %>% 
  left_join(cover %>% select(coverscale,cover_code,cover_perc))
```

The output contains these variables

```         
 "releve_nr"     "species_nr"    "cover_code"    "layer"         "orig_name"     "kaplan"        "expert_system" "nonvascular"   "coverscale"    "cover_perc"   
```

If I am satisfied with the result I assign the pipeline into the *spe* file. I still want to add one more line to remove nonvasculars (mosses) and add one more line to select just needed variables. I decided to follow the concept saved in the *expert_system name* and I renamed it directly in the `select` function

```{r}
spe<- tvabund %>% 
  left_join(nomenclature %>% 
              select(species_nr, kaplan, expert_system, nonvascular)) %>% 
  left_join(env %>% select(releve_nr, coverscale)) %>% 
  left_join(cover %>% select(coverscale,cover_code,cover_perc)) %>%
  filter (!nonvascular==1) %>%
  select(releve_nr, species= expert_system, layer, cover_perc)
```

To see the result we will use view

```{r}
view(spe)
```

We can again save the final file, to be easily accessible for later

```{r}
#| eval: false
write.csv(spe, "data/turboveg_to_R/spe.csv")
```

## 11.5 Merging of species covers

### 11.5.1 Duplicate species records

What is the problem? Sometimes we have some species names listed more than once in the same plot. Either because we changed the original concept (from subspecies to species level, or after additional identification) or because we recorded the same species in different layers. Depending on our further questions and analyses this might become minor or bigger problem.

![](images/clipboard-3634652959.png)

**A**\> In the first case, duplicate within one layer, I can fix the problem by summing the values for the same species in the same layer to get distinct species-layer combinations per plot. This is something we need to do. Otherwise our data would go against tidy approach and we will experience issues in joins, summarisation etc.

**B**\> In the other case, duplicate across layers, the data are OK, because there is one more variable that makes it unique record (layer). But if we want to look at the whole community and e.g. calculate share of some life forms weighted by cover, etc. we again need to sum the values across layers and put all the species as they were in the same layer (this is then usually marked as 0).

### 11.5.2 Duplicates checking

We recommend to always do the following check of the data. Simply group species by releves/plots and count if some of the species are at more rows.

```{r}
spe %>% 
  group_by(releve_nr, species, layer) %>% 
  count() %>%
  filter(n>1)
  
```

We can see that in two releves/plots there is a conflict in the species *Galium palustre* agg. Most probably we separated two species in the field that we later on decided to group into this aggregate. We can go back and check where exactly this happened, by exactly specifying where to look.

```{r}
tvabund %>% 
  select(releve_nr, species_nr)%>%
  left_join(nomenclature %>% 
              select(species_nr, turboveg= turboveg_czechia_slovakia, 
                     species=expert_system)) %>%
  filter(releve_nr %in% c(132, 183182) & species =="Galium palustre agg.")
  
```

Alternatively, I can save the first output and use semi-join function, which is very useful if there are more rows I want to check and I do not need to specify multiple conditions in the filter.

```{r}

test<-spe %>% 
  group_by(releve_nr, species, layer) %>% 
  count() %>%
  filter(n>1)


tvabund %>% 
  select(releve_nr, species_nr)%>%
  left_join(nomenclature %>% 
              select(species_nr, turboveg= turboveg_czechia_slovakia, 
                     species=expert_system)) %>%
  semi_join(test)
```

OK, I understand why it happened and I have to fix it now. But we continue checking. Now we will check if there is also problem with species across layers (B). I will simply change the grouping conditions, to the higher hierarchy.

```{r}
spe %>% 
  group_by(releve_nr, species) %>% 
  count() %>%
  filter(n>1)
```

We got lot of duplicates, right? But it is understandable in the vegetation type we have. So keep it in mind for later analyses.

Sometimes it is actually good to take some extra time and just look at what is inside. Are there just trees recorded also as shrubs and juveniles or are there some herbs by mistake included in tree layer? Use view to see the whole list.

```{r}
spe %>% 
  distinct(species,layer)%>%
  group_by(species) %>% 
  count() %>%
  filter(n>1) 
```

### 11.5.3 Fixing duplicate rows

Now finally the fixing. For some questions the most easiest thing how to resolve duplicate rows is to select only the relevant variables and groups and use distinct function. E.g. for species richness this would be enough. BUT we will lose information about the abundance, in our case percentage cover of each species.

```{r}
spe %>% 
  distinct(releve_nr, species,layer)
```

The percentage cover is estimated visually relative to the total area. In the field it is estimated indepently of other plants, because we know that the plants overlap within vertical space. If we use normal sum function, we can easily get total cover per plot above 100%. Although we can separate the information into vegetation layers, it is still rather coarse division. Especially in grasslands where the main diversity is in just one, often very dense, layer.

Therefore we will use the approach suggested by H.S. Fischer in the paper *On combination of species from different vegetation layers* (AVS 2014), where he suggested summing up covers considering overlap among species, so that the overall maximum value is 100 and all the values are adjusted relative to this treshold. We will prepare function called `combine_cover`

```{r}
combine_cover <- function(x){
  while (length(x)>1){
    x[2] <- x[1]+(100-x[1])*x[2]/100
    x <- x[-1]
  }
  return(x)
}
```

**A,** Now let's check how it works. We will first fix the issue with duplicates within the same layer (A)

```{r}
spe %>% 
  group_by(releve_nr, species, layer) %>% 
  summarise(cover_perc_new = combine_cover(cover_perc)) 
```

and we will add the pipelines for checking if there are still some duplicate rows. Note `summarise` finished the `group_by` function, so I have to specify the grouping again in the `count` (or add the group_by before count again).

```{r}
#| warning: false
spe %>% 
  group_by(releve_nr, species, layer) %>% 
  summarize(cover_perc_new = combine_cover(cover_perc))%>%
  count(releve_nr, species, layer) %>%
  filter(n>1)
```

When the output have no rows, it means our attempt solved the issue.

If I am happy, I overwrite cover directly, save the output for easier access (next time you can start with reloading this file) or I will assign the whole pipeline into a new object e.g. -\>*spe_merged*

```{r}
#| warning: false
spe %>% 
  group_by(releve_nr, species, layer) %>% 
  summarize(cover_perc = combine_cover(cover_perc))%>%
  write_csv("data/turboveg_to_R/spe_merged_covers.csv")

```

**B,** We want to also remove information about layer and work at whole community level. This means we will do the same, we will just not add the layer into grouping, as we do not want to pay attention to it anymore.

```{r}
#| warning: false
spe %>% 
  group_by(releve_nr, species) %>% 
  summarize(cover_perc = combine_cover(cover_perc))%>%
  write_csv("data/turboveg_to_R/spe_merged_covers_across_layers.csv")
```

### 11.5.4 Total cover of all species in the plot

The same approach as we did for merging covers can be used also for calculating total cover in the plot. Here you can see the comparison of total cover calculated as ordinary sum and total cover calculated with considering the overlaps.

```{r}
#| warning: false
spe %>% 
  group_by(releve_nr) %>% 
  summarize(covertotal_sum = sum(cover_perc), 
            covertotal_overlap = combine_cover(cover_perc)) %>%
  select(releve_nr, covertotal_sum, covertotal_overlap)%>%
  arrange(desc(covertotal_sum))
```

The same with respect to layers

```{r}
#| warning: false
spe %>% 
  group_by(releve_nr, layer) %>% 
  summarize(covertotal_sum = sum(cover_perc), 
            covertotal_overlap = combine_cover(cover_perc)) %>%
  select(releve_nr, layer, covertotal_sum, covertotal_overlap)
```

## 11.6 Joining information about traits and other variables

We will first read the data newly, to be sure we know what we are working with. At this point we can actually clean the environment, remove everything.

### 11.6.1 env dataset

First I want to add some more variables that were measured separately. In addition this file is already filtered to a subset I want to use.

```{r}
env_extra<- read_csv("data/turboveg_to_R/axmanova_forest_env_extra.csv")%>%
  clean_names()
```

For **env dataset** I want to import the clean version which was saved in this script, but I will directly filter it to the same subset as above. I can do it with semi_join. But I decided to merge both datasets at this point - to keep only the matching rows but all information I want.

```{r}
env<- read_csv("data/turboveg_to_R/env.csv") %>% 
  inner_join(env_extra %>% 
               select (releve_nr, forest_type, forest_type_name,
                       soil_ph=p_h_k_cl, biomass)%>% 
               unite(forest, forest_type, forest_type_name))
```

### 11.6.2 spe dataset

I want to work with the **spe dataset**, and I want to keep information about layers, as I want to focus on the herb-layer.

```{r}
spe <- read_csv ("data/turboveg_to_R/spe_merged_covers.csv")%>% 
  semi_join(env)
```

### 11.6.3 traits

I also want to add some information about traits. So I will check what is available in my folder

```{r}
list.files("data/turboveg_to_R")
```

First we will import the file downloaded from the Pladias database, with information about status. The file itseslf is in Czech and it needs some fixing to make it tidy. Below, you can already find one suggestion how to import this file, but we will check together how to read it and how it works step by step.

```{r}
status <- read_excel("data/turboveg_to_R/Pladias-taxony-puvod-invazni-status-cerveny-seznam-ochrana-2023-11-06.xlsx") %>% 
  clean_names()%>% 
  select(species=vedecke_jmeno, origin=puvodnost_v_cr, 
         redlist=cerveny_seznam_2017_narodni_kategorie_ohrozeni)%>%
  mutate(origin = case_when(
    origin == "původní" ~ "native",
    origin %in% c("archeofyt/neofyt", "archeofyt") ~ "arch",
    origin == "neofyt" ~ "neo",
    TRUE ~ NA_character_))%>% 
  mutate(redlist = case_when(
    redlist == "taxon není zařazen do Červeného seznamu" ~ NA_character_,
    TRUE ~ redlist))
```

Now we will import data about plant height, again there are few issues, so we will fix it and calculate the mean height.

```{r}
plant_height <- read_excel("data/turboveg_to_R/Vyska.xlsx") %>% 
  clean_names() %>% 
  select(species=taxon, height_min=min, height_max=max)%>% 
  mutate(across(c(height_min, height_max), ~ as.numeric(.x)))%>%
  mutate(height_mean = ((height_min+height_max)/2))
```

And Ellenberg indicator values

```{r}
#| warning: false
indicator_values <- read_excel("data/turboveg_to_R/ekologicke_indikacni_hodnoty.xlsx") %>% 
  clean_names() %>% 
  select(species=name, 
         eiv_light=l_cz, eiv_temperature=t_cz, 
         eiv_moisture=m_cz, eiv_reaction=r_cz, 
         eiv_nutrients= n_cz, eiv_salinity=s_cz)%>%
  mutate(across(-species, ~ as.numeric(.x)))
```

## 11.7 Summary statistics and graphical outputs

I will a bit explore the data and ask about which factors influence species richness. Here are just few examples, we will read together the scripts and you will adopt them later to other tasks. First I want to produce a table with **summary statistics** like min, mean, max for two variables plant height, and biomass per forest type. The first one is a trait, so we need to append it to species file and calculate community means, while the other is a variable measured in each plot.

```{r}
statistics <- spe %>% 
  filter(layer == "6") %>%
  left_join(plant_height %>% 
              select(species, height = height_mean)) %>%
  left_join(env) %>%
  arrange(forest) %>%
  summarise(across(c(height,cov_herbs, biomass, cov_trees,soil_ph ),
      list(
        min  = ~min(.x, na.rm = TRUE),
        mean = ~mean(.x, na.rm = TRUE),
        max  = ~max(.x, na.rm = TRUE))),.by = forest)
```

Or I can create **boxplots** for these, one by one or with the use of function (see chapter 7+8).

```{r}
env %>%
  ggplot(aes(forest, biomass)) +
  geom_boxplot()+
  theme_bw()
```

Alternatively I can also do it like this, that I save the values to long format and use facet_wrap to create more boxplots at once:

```{r}
env %>%
  arrange(forest) %>%
  select(forest, cover_herbs=cov_herbs, biomass, cover_trees =cov_trees, soil_ph) %>%
  tidyr::pivot_longer(
    cols = c(cover_herbs, biomass, cover_trees, soil_ph),
    names_to = "variable",
    values_to = "value")%>% 
  ggplot(aes(x = forest, y = value, fill=forest)) +
  geom_boxplot() +
  facet_wrap(~ variable, scales = "free_y") +
  theme_bw() +
  theme(legend.position = 'none')+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = NULL) +
  labs (y = NULL)
```

I might be interested in **species richness relationship** with several factors. Below is an example of herb-layer species richness and biomass. At first I need to calculate the species richness in the spe file. And as an output I want to plot this with different colours for different forest types but keep the regression line for the whole dataset.

```{r}
spe %>% 
  filter(layer %in% c(6, 7)) %>% 
  count(releve_nr, name = "herblayer_richness") %>% 
  left_join(env %>% 
              select(releve_nr, biomass, forest), by = "releve_nr") %>% 
  ggplot(aes(x = sqrt(biomass), y = herblayer_richness)) +
  geom_point(aes(colour = forest), size = 2, alpha = 0.8) +
  geom_smooth(method = "lm", se = TRUE, colour = "black") +
  theme_bw() +
  labs(
    x = "sqrt Biomass",
    y = "Herb-layer species richness",
    colour = "Forest type"
  )
```

**Boxplots of Ellenberg-type indicator values** are based again on species data and values specific for each species. We will calculate non-weighted mean for each plot and prepare boxplots for individual forest types. Again I will use the step with long format and facet wrap.

```{r}
spe %>% 
  left_join(indicator_values) %>%
  select(-c(layer, cover_perc)) %>%
  distinct() %>%
  group_by(releve_nr) %>%
  summarise(across(starts_with("EIV"), ~ mean(.x, na.rm = TRUE))) %>%
  left_join(env %>% select(releve_nr, forest))%>%
  pivot_longer(
    cols = starts_with("EIV"),
    names_to = "EIV_variable",
    values_to = "value")%>%
  ggplot(aes(x = forest, y = value, fill = forest)) +
  geom_boxplot() +
  facet_wrap(~ EIV_variable, scales = "free_y") +
  theme_bw()+
  theme(legend.position = 'none')+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = NULL) +
  labs (y = NULL)

```

**Proportions of endangered or alien species** in forest type. I will first look at the numbers of these species, here on example of redlist i.e. endangered species. I just one to see average number of redlist species per forest type.

```{r}
spe%>% 
  left_join(spe %>% 
              left_join(status)%>% 
              filter(!is.na(redlist))%>%
              count(releve_nr, name="richness_redlist"))%>%
  left_join(spe %>% 
              summarise(richness_all = n_distinct(species), 
                        .by = releve_nr))%>%
  distinct(releve_nr,richness_redlist,richness_all)%>%
  mutate(richness_redlist = replace_na(richness_redlist, 0))%>%
  mutate(richness_redlist_perc= richness_redlist/richness_all*100)%>%
  left_join(env%>% select(releve_nr, forest))%>%
  summarise(redlist_mean_perc = mean(richness_redlist_perc), .by=forest)%>%
  arrange(forest)
```

But I can also ask about diferences in abundances of some plant groups. What is the proportion of cover of alien species relative to total cover in different forests?

```{r}
spe%>% 
  left_join(spe %>% 
              left_join(status)%>% 
              filter(origin %in% c("arch","neo"))%>%
              summarize(cover_alien = combine_cover(cover_perc), 
                        .by=releve_nr))%>%
  left_join(spe %>% 
              summarize(cover_total = combine_cover(cover_perc), 
                        .by=releve_nr))%>%
  distinct(releve_nr, cover_alien, cover_total)%>%
  mutate(cover_alien = replace_na(cover_alien, 0))%>%
  mutate(cover_alien_perc= cover_alien/cover_total*100)%>%
  left_join(env%>% select(releve_nr, forest))%>%
  summarise(alien_cover_mean_perc = mean(cover_alien_perc), .by=forest)%>%
  arrange(forest)
```

## Almost at the end of this course!

A couple of tidyverse songs as a bonus that you stayed with us and learned many new things:

Human-made: <https://www.youtube.com/watch?v=p8Py9C8iq2s>

AI-made: <https://suno.com/song/0599ca04-d17b-4fbd-8e3c-1a1a8a21e446?sh=iVMVs4IoyAXEoZMo>

## 11.8 Exercises

### These should be handed in for successful finishing of this course.

1.  **Forest dataset from Turboveg database** - prepare script from the database files as described above and (1) prepare scatterplot of a) overall species richness and b) herb-layer species richness against soil pH (2) scatterplot of herb-layer species richness against cover of trees (3) boxplots of richness (number of species) of native species, redlist species and alien species.

2.  Use the data from the folder **basiphilous_grasslands** and recreate the following plot. Note that some data handling will be needed before you start plotting (transform the species abundance data from wide to long format, join species characteristics, calculate the number of species and number of specialists (`THE_THF`) for each plot (Releve), join header data and transform the variable for the time of sampling (`Rs_observ`) to a character/factor).

    ![](images/clipboard-3338851266.png)

3.  **Frogs** Use the data of the 10 most common frog species recorded within the Australian [FrogID initiative](https://www.frogid.net.au/explore). The original data comes from the [TidyTuesdays repository](https://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-09-02/readme.md), but we modified it slightly for this exercise and stored it in the `frogs` folder of our [repository](https://github.com/BotzoolDataAnalysis/BotzoolDataAnalysis.github.io/tree/main/DataManipulationVisualisation/data). The data are stored in multiple csv files, one for each species. Load all these files using a single pipeline (with `map`) and save to your environment as a single tibble \>\> prepare two barplots, first showing number of species in each stateProvince, and second showing number of all records irrespective of species \>\> prepare a table where there will be species as rows, columns for each stateProvince and values will represent the absolute number of records \>\> calculate also relative variables which will show representation of each species in the stateProvince relative to all species (%) in the stateProvince.

4.  **Lepidoptera** Work with this dataset, namely `spe_matrix_MSvejnoha`, which is the species file with counts of moths in forest steppe localities. Import the data and check the structure \>\> count number of all individuals at each site i.e. abundance of moths \>\> from the env file import for each site cover of herbs, shrubs, trees and dead wood \>\> prepare suitable graphs to visualise the relationship between abundance of moths and these variables characterising the vegetation.

5.  **Acidophilous grasslands** Import the head dataset, transform latitude and longitude into deg_lat and deg_long format \>\>prepare map with sites/sampled localities \>\> for vegetation types (syntax_new) with more than 15 plots/samples prepare boxplots with comparison of species richness in old and new plots (information about new plots can be identified in the head as those sampled by M. Harásek, indicated as resampled).
