---
title: "7 + 8 Automatisation"
author: "Klára Friesová"
bibliography: references.bib
csl: apa.csl
link-citations: true
format: html
---

> "Copy-and-paste is a powerful tool, but you should avoid doing it more than twice." – Hadley Wickham, R for Data Science

It's not only a matter of the script length. Repeating the same code multiple times might easily lead to errors and inconsistencies, and it is therefore better to avoid it. There are multiple ways to reduce copy-pasting when we want to repeat a similar operation multiple times. In this chapter, you will learn how to write your own **function** and some tools for **iteration,** including **for loops** and functions from the `purrr` package.

Throughout this chapter, we will use the following packages:

```{r}
#| warning: false
library(palmerpenguins)
library(broom)
library(tidyverse)
```

## 7.1 Functions

In more complex data analysis tasks, when you need to repeat a similar operation multiple times, e.g. calculate the same model for multiple subsets of data, calculate models with the same explanatory variables for different response variables, or draw similarly looking plots for multiple variables, it becomes really useful to be able to write your own function and hide the repeated code into it. A huge advantage of only writing the code once and saving it as a function is that when you have to change something, you only do it once and thus prevent mistakes like replacing the variable name in one place but not in the other, etc. In the long term, it also saves time and improves the understandability of the code, as the script does not end up being hundreds or thousands of lines long and all important commands are in one place.

We will use a penguin dataset that you know already:

```{r}
glimpse(penguins)
```

### 7.1.1 Vector functions

Let's say we want to standardise each measured variable in the dataset, and just imagine for now that there is no `scale()` function, so we have to do it manually. We would end up with something like this:

```{r}
penguins |> 
  mutate(bill_length_mm = (bill_length_mm - mean(bill_length_mm, na.rm = T))/sd(bill_length_mm, na.rm = T), 
         bill_depth_mm = (bill_depth_mm - mean(bill_depth_mm, na.rm = T))/sd(bill_depth_mm, na.rm = T),
         flipper_length_mm = (flipper_length_mm - mean(flipper_length_mm, na.rm = T))/sd(flipper_length_mm, na.rm = T),
         body_mass_g = (body_mass_g - mean(body_mass_g, na.rm = T))/sd(body_mass_g, na.rm = T))
```

When creating such a code, it is quite easy to forget to replace the variable name in one place when copying it. To avoid that and make the code easier to read, we can transform the code into a function. We need three things to do that:

1.  a **function name**, this should be concise and informative (please avoid `myfunction1()`, etc.) and not mess up already existing functions, we will use `custom_scale` to distinguish our function from the `scale()`.
2.  **arguments**, which are the things that we want to vary across calls, in our case, we have just one numerical variable we are working with, so we will call it `x`.
3.  **body**, that is the code that stays the same across calls.

Every function defined in R has the following structure:

```{r}
#| eval: false

name <- function(arguments){
  body
}
```

In our case, the function would look like this:

```{r}
custom_scale <- function(x){
  (x - mean(x, na.rm = T))/sd(x, na.rm = T)
}
```

When we run this code, our new function is saved into the environment, and we can use it as any other function. We created a function that takes a vector and returns a vector of the same length that might be use within the `mutate()` function.

```{r}
penguins |> 
  mutate(bill_length_mm = custom_scale(bill_length_mm), 
         bill_depth_mm = custom_scale(bill_depth_mm),
         flipper_length_mm = custom_scale(flipper_length_mm),
         body_mass_g = custom_scale(body_mass_g))
```

We can, of course, reduce the duplication even further by using the `across()` function:

```{r}
penguins |> 
  mutate(across(c(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g), ~custom_scale(.x)))
```

There are some useful RStudio keyboard shortcuts you can use to work with functions:

-   To find a definition of any function, place a cursor on the name of the function in the script and press `F2`.

-   To extract a function from a code you have written, use `Alt + Ctrl + X`. Just be sure you always check the results, because sometimes it will not do exactly what you expect, so you will have to make some adjustments.

We can also write summary functions to be used in a `summarise()` call. For example, we could calculate the difference between the minimum and maximum values of the given variable:

```{r}
range_diff <- function(x){
  max(x, na.rm = T) - min(x, na.rm = T)
}

penguins |> 
  summarize(bill_length_mm = range_diff(bill_length_mm), 
            bill_depth_mm = range_diff(bill_depth_mm))
```

### 7.1.2 Data frame functions

Till now, we have written several vector functions that might be used within `dplyr` functions. But functions may operate even at the data frame level. We will show here a real-world example of data sampled in three types of sand vegetation - pioneer sand vegetation (*Corynephorion*), acidophilous sand grasslands (*Armerion*) and basiphilous sand grasslands (*Festucion valesiacae*). The species data of all three vegetation types are saved in a long format in one file, and the header data with cluster assignment in a second file.

```{r}
spe_long <- read_csv('data/sands/sands_spe_long.csv')
glimpse(spe_long)

head <- read_csv('data/sands/sands_head.csv') |> 
  select(releve_nr, cluster)
glimpse(head)
```

Imagine we now want to run an ordination analysis that needs species data in a wide format for each of the three vegetation types separately. We need to subset the species data to only the selected vegetation type, select only relevant columns, square-root the species abundances, and transform the data into a wide format. We can incorporate all these steps into a single function, that we will then run three times for different subsets:

```{r}
subset_to_wide <- function(data_long, veg_type){
  data_long |> 
    semi_join(head |> filter(cluster == veg_type)) |>
    select(releve_nr, valid_name, cover_perc) |> 
    mutate(cover_perc = sqrt(cover_perc)) |> 
    pivot_wider(names_from = valid_name, values_from = cover_perc, values_fill = 0) |> 
    select(-releve_nr)
}

spe_wide_cory <- subset_to_wide(spe_long, 'Corynephorion')
spe_wide_arm <- subset_to_wide(spe_long, 'Armerion')
spe_wide_fes <- subset_to_wide(spe_long, 'Festucion valesiacae')
```

Writing your own functions with the `dplyr` and `tidyr` calls inside sometimes also brings some challenges. We unfortunately do not have enough space here to deal with them, but there are great sources with detailed explanation, where you can learn more or find help if needed, e.g. <https://r4ds.hadley.nz/functions.html#data-frame-functions>, [programming with dplyr](https://dplyr.tidyverse.org/articles/programming.html), [programming with tidyr](https://tidyr.tidyverse.org/articles/programming.html), [What is data-masking and why do I need {{?](https://rlang.r-lib.org/reference/topic-data-mask.html).

### 7.1.3 Plot functions

Sometimes it is also useful to reduce the amount of replicated code when plotting many different things in a similar way. The plot functions work similarly to the data frame functions, just return a plot instead of a data frame. For example, we might want to visualise the relationship between bill length and bill depth of three different penguin species separately. We have to first filter our penguin dataset to contain data on only one species, and then create a scatterplot using a `ggplot` sequence. This is how we would write the code for plotting the data for one species:

```{r}
penguins |> 
    filter(species == 'Adelie') |> 
    ggplot(aes(bill_length_mm, bill_depth_mm)) +
    geom_point() +
    theme_bw() +
    labs(title = 'Adelie', x = 'Bill length [mm]', y = 'Bill depth [mm]')
```

Let's now turn this code into a function instead of copy-pasting it two more times to plot the same relationship for the two other species:

```{r}
plot_species <- function(data, species_name){
  data |> 
    filter(species == species_name) |> 
    ggplot(aes(bill_length_mm, bill_depth_mm)) +
    geom_point() +
    theme_bw() +
    labs(title = species_name, x = 'Bill length [mm]', y = 'Bill depth [mm]')
}
plot_species(penguins, 'Adelie')
```

To learn more about reducing duplication in your `ggplot2` code look here: <https://r4ds.hadley.nz/functions.html#plot-functions>, [Programming with ggplot2](https://ggplot2-book.org/programming.html), <https://ggplot2.tidyverse.org/articles/ggplot2-in-packages.html>.

## 7.2 For loops

We will now move to the iteration part of this chapter, which means repeating the same action multiple times on different objects. In any programming language, it is possible to automate such repetitions using a **for loop**. The basic structure of a for loop looks like this:

```{r}
#| eval: false
for (variable in sequence) {
  # do something with the variable
}
```

The for loop takes one variable from a given sequence, runs the code inside `{}` for this variable and then moves to the next variable in the sequence. A basic example might be printing numbers from a sequence:

```{r}
for (i in 1:5) {
  print(i)
}
```

The for loop takes one number, prints it, then takes the next one, prints it, and so on till the end of the sequence.

We can, for example, take our plot function to plot the scatterplot of bill length and bill depth of individual species and loop over the species names to sequentially make a plot for all species.

```{r}
for (species_name in unique(penguins$species)) {
  plot_species(penguins, species_name) |> 
    print()
}
```

There are always multiple ways to get to the same result, and this is also true for iteration in R. The `purrr` package has powerful tools to iterate over multiple elements. Once the problems become more complex, it becomes more effective to use `purrr` functions in a pipeline instead of complicated nested for loops. But even when you choose to prefer `purrr` solutions, it is worth being familiar with for loops and their functionality, because you might see them often in the code of other people, and they are universal across programming languages.

## 7.3 purrr and working with nested dataframes

### 7.3.1 Basic usage of `purrr`

We already went through most of the `tidyverse` packages, but we didn't talk about the `purrr` package yet. `purrr` provides powerful tools for automatisation of tasks that need to be repeated multiple times, e.g. for each file in a directory, each element of a list, each dataframe... They allow you to replace for loops with `map()` functions, which might be more powerful, readable and consistent with the rest of `tidyverse`.

The `map()` function works similarly to `across()`, but instead of applying a function to each column in a data frame or tibble, it applies a function to each element of a vector or list. It is an analogy of a for loop, the function takes each element of a sequence and applies a function to it. Let's look at the difference between the for loop and `map()` in the following example:

```{r}
# for loop
for (i in 1:5) {
  print(i)
}
```

```{r}
map(1:5, ~.x)
```

The structure of the `map()` function may already be familiar to you, as it resembles that of the `across()`. Note the difference between the output of the for loop and `map()`. In the output of the for loop, we see `[1] 1`, whereas `map()` returns `[[1]] [1] 1`. This is because the `map()` function returns a **list**. We can save the output to an object and look at the structure.

```{r}
map_out <- map(1:5, ~.x)
```

In the environment, you will see it is a list, we can also explore the structure using `View()`. The individual values inside the list are called using double square brackets e.g., `map_out[[1]]`. This might be helpful to remember for further work with lists and `map()` functions.

```{r}
map_out[[1]]
```

In addition to `map()`, `purrr` contains also several relatives, which return different output types:

-   `map()` makes a list

-   `map_lgl()` makes a logical vector

-   `map_int()` makes an integer vector

-   `map_dbl()` makes a double vector

-   `map_chr()` makes a character vector

Each of the above-mentioned functions takes a vector input, applies a function to each element and returns a vector of the same length.

-   `map2()` takes two vectors, usually of the same length and iterates over two arguments at a time

And there is also a group of `walk()` functions, which return their side-effects and return the input `.x`. They might be used, for example, for saving multiple files or plots.

We will now look at several examples of their usage. We can use the `map()` function to apply any function to multiple elements. It becomes very useful for working with lists. As a basic example, we can apply a simple function like `sqrt()` to every element of a list.

```{r}
test_list <- list(2, 4, 6, 8, 10)

map(test_list, ~sqrt(.x))
```

To get a numeric vector output, we can use the `map_dbl()` function.

```{r}
map_dbl(test_list, ~sqrt(.x))
```

And we can also write it with the pipe:

```{r}
test_list |> map_dbl(~sqrt(.x))
```

We can also rewrite our for loop used for creating plots of the relationship between penguin bill length and bill depth separately using a map function:

```{r}
map(unique(penguins$species), ~plot_species(penguins, .x))
```

The huge advantage of such an approach becomes more visible once we start, e.g., working with multiple datasets with the same structure, building the same models for different variables, or plotting many plots.

`map2()` takes two vectors or lists of the same length and iterates over them in pairs. We can illustrate this on the following example, where we will combine two lists with character strings in a single one:

```{r}
genus <- list('Acer', 'Quercus', 'Tilia', 'Fagus')
species <- list('platanoides', 'petraea', 'cordata', 'sylvatica')

map2(genus, species, ~str_c(.x, .y, sep = ' '))
```

The `str_c()` function from the `stringr` package combines two or more character strings in one, we specify the elements that should be combined and the separator that should be placed in between. Note that we now have two arguments to iterate over, and thus we must use two placeholders, `.x` and `.y`, where `.x` represents the first argument of `map2()` and `.y` represents the second.

We can also use the relatives `map2_dbl()`, `map2_chr()` etc., to create a single vector. In the case of the species names the result is a character, so we will use `map2_chr()`.

```{r}
map2_chr(genus, species, ~str_c(.x, .y, sep = ' '))
```

### 7.3.2 Loading multiple files

Let's begin with the task of reading multiple files simultaneously. Imagine you have multiple files with the same structure, but for some reason, they are stored in separate files. As example data, we will use the [gapminder](https://www.gapminder.org/data) dataset, which provides values for life expectancy, GDP per capita, and population size. The data we have in the `gapminder` folder ([Link to the Github folder](https://github.com/BotzoolDataAnalysis/BotzoolDataAnalysis.github.io/tree/main/DataManipulationVisualisation/data)) is divided by year, and we now want to load them all and combine them into a single tibble. We could do that by copy-pasting the `read_csv()` function twelve times, but there is a more elegant way. Let's list the files first:

```{r}
paths <- list.files('data/gapminder/', pattern = '.csv', full.names = T)
paths
```

Now we can use the `map()` function to load all these datasets from a single line of code:

```{r}
files <- map(paths, ~read_csv(.x))
str(files)
```

We got a list with 12 tibbles. To access the first element of the list, we would call `files[[1]]`.

```{r}
files[[1]]
```

Now we want to combine all these tibbles into a single one, which can be done using the `list_rbind()` function:

```{r}
#| warning: false
gapminder_df <- map(paths, ~read_csv(.x)) |> 
  list_rbind()
glimpse(gapminder_df)
```

But we somehow lost the information about the year, which was stored in the file names. To fix it, we now store the file names in the data frame. The first step is to set the names of the list elements of `paths`. The `basename()` function extracts just the file name from the path.

```{r}
paths |> 
  set_names(basename)
```

We now got the file name to the name of each element of `paths`. Second, we combine this step with the `map()` for reading multiple csv files. In `list_rbind()`, we save the names in the resulting data frame to a column called `year`.

```{r}
#| warning: false
gapminder_df <- paths |> 
  set_names(basename) |> 
  map(~read_csv(.x)) |> 
  list_rbind(names_to = 'year')
glimpse(gapminder_df)
```

Still not perfect, it would be nice to extract just the year from the file name. The easiest way to do it in this case is to use the `parse_number()` function that extracts just a number from a string:

```{r}
#| warning: false
gapminder_df <- paths |> 
  set_names(basename) |> 
  map(~read_csv(.x)) |> 
  list_rbind(names_to = 'year') |> 
  mutate(year = parse_number(year))
glimpse(gapminder_df)
```

It might be a good idea to save the resulting data frame as a single csv file now to make future data loading easier.

```{r}
write_csv(gapminder_df, 'data/gapminder_clean/gapminder.csv')
```

### 7.3.3 Writing multiple files

Similarly, we can also save multiple files at once. Let's say we want to save our gapminder data divided by continent.

We first have to create a **nested data frame** nested by continent. This is similar to `group_by()`, we take a variable that makes groups in our dataset and divide the rest of the data according to this variable. In the case of `group_by()`, our data stays in a single tibble. `nest()` creates a nested tibble, which means that the grouping variable stays in one column, and a smaller tibble is created for each level of this variable. All these smaller data frames are stored in the `data` column.

```{r}
gapminder_df |> 
  nest(.by = continent)
```

We want to save each of these smaller data frames as a separate csv file. To give the files informative names, we now create a column where we define a path for each file to be saved.

```{r}
gapminder_nest <- gapminder_df |> 
  nest(.by = continent) |> 
  mutate(path = paste0('data/gapminder_continent/gapminder_', continent, '.csv')) 

glimpse(gapminder_nest)
```

We can see that the `data` column is a list containing tibbles with different numbers of rows, but the same number of columns. To look at one of them, we need to use the `[[]]` again.

```{r}
gapminder_nest$data[[1]]
```

To save all the tibbles in separate csv files, we will use the `walk2()` call, which at each step takes one tibble from the `data` column and one path definition from the `path` column and runs the `write_csv()` function with these two arguments.

```{r}

walk2(gapminder_nest$data, gapminder_nest$path, ~write_csv(.x, .y))
```

### 7.3.4 Multiple models

Working with nested data frames becomes particularly helpful when we need to perform the same calculation multiple times. We will work with the `gapminder` data again and try to answer the following questions: How does life expectancy change over time in individual countries? In which countries has the life expectancy risen the most over time?

To explore the data a little bit first, we can plot them:

```{r}
gapminder_df |> 
  ggplot(aes(year, lifeExp, group = country)) +
  geom_line()
```

Overall, life expectancy has been steadily increasing over time, but we need some estimation of the trend in individual countries. A possible way to do this would be to fit a linear model to the data from each country and look at the estimate. Given the 142 countries in the dataset, we really do not want to run the code for each one manually with copy-pasted code. Because we want to work at the country level, we will now nest our data by country.

```{r}
by_country <- gapminder_df |> 
  nest(.by = country)
by_country
```

To calculate a linear model for data from each country, we will iterate over the `data` column and save the resulting model to a new column. This might be done with `map()` within the `mutate()` call.

```{r}
by_country <- gapminder_df |> 
  nest(.by = country) |> 
  mutate(m = map(data, ~lm(lifeExp~year, data = .x)))
by_country
```

The column `m` we just created is again a list and contains the results of linear models for the relationship between life expectancy and time for all countries. With each one of them, we can do whatever is possible with a model result:

```{r}
summary(by_country$m[[1]])
```

To easily extract the estimates from the model, we will use `tidy()` function from the `broom` package. `broom` is not part of the `tidyverse`, but it is a related package, which becomes very helpful when working with models within the `tidyverse` workflow, because it provides tools to convert statistical objects into tidy tibbles. The `tidy()` function summarises information about the model components:

```{r}
tidy(by_country$m[[1]])
```

And we can again use it to iterate over all models to get these summaries for all countries.

```{r}
by_country <- gapminder_df |> 
  nest(.by = country) |> 
  mutate(m = map(data, ~lm(lifeExp~year, data = .x)), 
         m_tidy = map(m, ~tidy(.x)))

glimpse(by_country)
```

The summary is now in a tibble, but there is still a list of tibbles in the `m_tidy` column. To get the results to a data frame where we can sort the values and filter across all values, we need to `unnest()`.

```{r}
by_country <- gapminder_df |> 
  nest(.by = country) |> 
  mutate(m = map(data, ~lm(lifeExp~year, data = .x)), 
         m_tidy = map(m, ~tidy(.x))) |> 
  unnest(m_tidy)

glimpse(by_country)
```

We now have one column for each column originally included in the tibbles inside `m_tidy`. The list-columns we did not unnest still remain list-columns. There are now two rows for each country, one for each model coefficient - the intercept and the year. We are not interested in model intercepts now, so we can filter them out. To see in which countries has the life expectancy risen the most over time, we can arrange the dataset according to the model estimate.

```{r}
by_country <- gapminder_df |> 
  nest(.by = country) |> 
  mutate(m = map(data, ~lm(lifeExp~year, data = .x)), 
         m_tidy = map(m, ~tidy(.x))) |> 
  unnest(m_tidy) |> 
  filter(term == 'year') |> 
  arrange(desc(estimate))

glimpse(by_country)
```

Or we can just print out the top 10 countries:

```{r}
by_country |> slice_max(estimate, n = 10)
```

The use of nested data frames and `broom` has great potential. Depending on the question, it is possible to filter only significant results, select models with the highest explanatory power, etc. To learn more about the automatisation using purrr and running many models, look here: <https://r4ds.hadley.nz/iteration.html>, <https://adv-r.hadley.nz/functionals.html>, <https://r4ds.had.co.nz/many-models.html>, <https://www.tmwr.org>.

### 7.3.5 Debugging

It is possible that the code may not work initially. To simplify iteration within `map()`, it is often helpful to perform the calculation for a single element of the list and try to identify the error there. We can do this by replacing `.x` by one element of our nested tibble.

```{r}
by_country <- gapminder_df |> 
  nest(.by = country) 

lm(lifeExp~year, data = by_country$data[[1]])
```

## 7.4 Exercises

1.  Rewrite the following code as a function:

    ```{r}
    #| eval: false
    x / sum(x, na.rm = T)*100
    y / sum(y, na.rm = T)*100
    z / sum(z, na.rm = T)*100
    ```

2.  Use the function to calculate the percentage of each species in the penguins dataset.

3.  Write your own function that takes a numeric vector of temperatures in Fahrenheit and returns them converted to Celsius using the formula $C = (F-32) *5/9$. Test it with the following values: 0°F, 20°F, 68°F, 86°F, 100°F.

4.  In Turboveg 2, a programme used for storing vegetation plot data, the geographical coordinates are stored in a format DDMMSS.SS. To show the plots in the map or perform any spatial calculations, you will need to transform the coordinates to decimal degrees. That is the purpose of the following function:

    ```{r}
    #| eval: false

     tv_to_degrees <- function(coord){
      as.numeric(str_sub(coord, 1, 2)) + as.numeric(str_sub(coord, 3, 4)) / 60 + as.numeric(str_sub(coord, 5, 11)) / 3600
    }
    ```

    Look at the function and try to explain how it works. Load the basiphilous grassland data (`basiphilous_grasslands/basiphilous_grasslands_S_Moravia_head.csv`, [Link to the Github folder](https://github.com/BotzoolDataAnalysis/BotzoolDataAnalysis.github.io/tree/main/DataManipulationVisualisation/data)) and use this function to transform coordinates in the fields `Longitude` and `Latitude`.

5.  Write a function that calculates the heat load index using measured values of slope and aspect in a vegetation plot. You will need the following formula [@mccune_equations_2002]:

    $$
    0.339 + 0.808 \cdot \cos\left(\frac{\text{latitude} \cdot \pi}{180}\right) \cdot \cos\left(\frac{\text{slope} \cdot \pi}{180}\right)- 0.196 \cdot \sin\left(\frac{\text{latitude} \cdot \pi}{180}\right) \cdot \sin\left(\frac{\text{slope} \cdot \pi}{180}\right)- 0.482 \cdot \cos\left(\frac{\left|180 - \left|\text{aspect} - 225\right|\right| \cdot \pi}{180}\right) \cdot \sin\left(\frac{\text{slope} \cdot \pi}{180}\right)
    $$

    0.339+0.808\**cos(DEG_LAT\**pi/180)\**cos(SLOPE\**pi/180)-0.196\**sin(DEG_LAT\**pi/180)\**sin(SLOPE*\*pi/180)-0.482\**cos((abs(180-abs(ASPECT-225)))\*pi/180)*\**sin(SLOPE*\*pi/180)

6.  Use the function to calculate the heat load index for vegetation plots in basiphilous grasslands (use the same data as in the previous exercise). \* Calculate species richness of the plots and plot the relationship between the heat load index and species richness. Select only plots sampled in 2022 which are more precisely located. (Use the species data `basiphilous_grasslands/basiphilous_grasslands_S_Moravia_species.csv`, transform them to the long format, calculate the number of species per plot and join this information to the header data before you start plotting).

7.  Write a function to calculate the logistic population growth using the formula $N_t = \frac{K}{1 + \left( \frac{K - N_0}{N_0} \right) e^{-r t}}$, where $N_0$ is the initial population, K the carrying capacity, r an intrinsic growth rate and t time. Run the function for the values $N_0 = 10$, K = 100, r = 0.3 and time varies from 1 to 20.

    K / (1 + ((K - N0) / N0) \* exp(-r \* t))

8.  \* Write a function that calculates the Shannon diversity index using the formula $H' = -∑p_i ln(p_i)$. Use the function to calculate Shannon diversity of each plot in the sand vegetation dataset.

9.  Take the Pokémon dataset (`read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv')`) and visualise the distribution of defense power of water-type Pokémon. Turn this code into a function that helps you draw a histogram of defense power for different Pokémon types. \* Try to generalize the code so that you can plot a distribution of any numerical variable.

10. Use the function in a for loop and create plots of the distribution of defense power for all Pokémon types. \* Save all plots in a `plots` folder.

11. Use a function from the `purrr` package to calculate the logaritm of each value in the following list: `test_list <- list(0, 1, 4, 8, 10)`. Save the output first as a list and second as a numeric vector. Compare the differences.

12. Take the following numeric vectors and use a function from the `purrr` package to multiply the first one by the second one. `num1 <- list(1, 2, 3, 4, 5, 6)`, `num2 <- list(7, 8, 9, 10, 11, 12)`. Save the output first as a list and second as a numeric vector. Compare the differences.

13. Use the function from exercise 9 and create plots of the distribution of defense power for all Pokémon types using functions from the `purrr` package.

14. In this exercise, we will use data of the 10 most common frog species recorded within the Australian [FrogID initiative](https://www.frogid.net.au/explore). The original data comes from the [TidyTuesdays repository](https://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-09-02/readme.md), but we modified it slightly for this exercise and stored it in the `frogs` folder of our [repository](https://github.com/BotzoolDataAnalysis/BotzoolDataAnalysis.github.io/tree/main/DataManipulationVisualisation/data). The data are stored in multiple csv files, one for each species. Load all these files using a single pipeline and save to your environment as a single tibble. Store the species names in a column in the final tibble.

15. \* Create a bar plot showing which frog species are most often recorded (to order the species from the most to the least common, use a function from the `forcats()` package). Add colour distinction of records from different territories (column `stateProvince`).

16. Save the frog data as separate csv files by territory, where the observations were made in a folder `frogs_territory`.

17. Use the Pokémon dataset, nest it by Pokémon type and calculate linear models for the relationship between defense and attack power (`lm(defense ~ attack)`) of each Pokémon type using a `map()` function within `mutate()`. Use the `tidy()` function to extract coefficients and p-values from the model. Unnest the list column where you saved the results of `tidy()`. For each Pokémon type, filter only statistics for the attack coefficient, keep only significant results (p \< 0.05) and arrange the dataset according to the coefficient from the linear model from Pokémon types where the relationship between defence and attack power is the strongest to those with the weakest relationship.

18. \* Take the code for visualisation of Ellenberg-type indicator values in different forest types (Exercise 5 in Chapter 6) and turn it into a function. Draw the boxplots for four different Ellenberg-type indicator values using this function. Use a for loop or `purrr` functions to make these four plots. Combine them and save them in the `plots` folder.

## 7.5 Further reading

R for Data Science: <https://r4ds.hadley.nz/program.html>

Hands on Programming with R: <https://rstudio-education.github.io/hopr>

Advanced R: <https://adv-r.hadley.nz>

Tidy Modeling with R: <https://www.tmwr.org>

Programming with dplyr: <https://dplyr.tidyverse.org/articles/programming.html>

Programming with tidyr: <https://tidyr.tidyverse.org/articles/programming.html>

Programming with ggplot2: <https://ggplot2-book.org/programming.html>

Tidy modeling with R: <https://www.tmwr.org>
