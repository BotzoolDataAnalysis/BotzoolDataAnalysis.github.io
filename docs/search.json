[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Botzool Data Analysis",
    "section": "",
    "text": "This is a website for the study materials related to the courses on data analysis at the Department of Botany and Zoology, Faculty of Science, Masaryk University.\nThe related courses are:\n\nBi7540 Anal√Ωza dat v ekologii spoleƒçenstev\nBi7542 Data analysis in community ecology\nBi8190 Manipulace a vizualizace dat v R (Data manipulation and visualisation in R)\n\nMoreover, this website contains guidelines for the use of AI in ecology.\n\nWebsite Navigation\n\nData Analysis in Community Ecology\nData Manipulation and Visualisation\nAI",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/6_advanced_visualisation.html",
    "href": "DataManipulationVisualisation/6_advanced_visualisation.html",
    "title": "6 Advanced Visualisation",
    "section": "",
    "text": "You already know how to make basic plots using ggplot functions. We‚Äôll now dive deeper into data visualisation tools in R and again use mostly ggplot2 package and its extensions.\nEvery plot in ggplot consists of 7 parts that together serve as instructions on how to draw a plot:\nTo produce any plot, ggplot needs data, mapping and at least one layer. The other parts have some defaults, but often need adjustments for better appearance.\nWe will again use the penguin dataset and play with the individual plot parts.\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶",
    "crumbs": [
      "Data Manipulation and Visualization",
      "6 Advanced data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/6_advanced_visualisation.html#faceting",
    "href": "DataManipulationVisualisation/6_advanced_visualisation.html#faceting",
    "title": "6 Advanced Visualisation",
    "section": "6.1 Faceting",
    "text": "6.1 Faceting\nFrom Chapter 3, you already know, how to visualise the relationship between the penguin bill length and bill depth.\n\npenguins |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, fill = species, shape = species)) +\n  geom_point() + \n  geom_smooth(aes(colour = species), method = 'lm', show.legend = F) + \n  scale_shape_manual(values = c(21, 22, 24)) + \n  labs(x = 'Bill length (mm)', y = 'Bill depth (mm)', fill = 'Species', shape = 'Species') + \n  theme_bw()\n\n\n\n\n\n\n\n\nBut what if we now want to look at the differences between males and females? We could change the definition of the fill and colour aesthetics, so that they display sex and keep just shape for species identity:\n\npenguins |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, fill = sex, shape = species)) +\n  geom_point() + \n  geom_smooth(aes(colour = sex), method = 'lm', show.legend = F) + \n  scale_shape_manual(values = c(21, 22, 24)) + \n  labs(x = 'Bill length (mm)', y = 'Bill depth (mm)', fill = 'Sex', shape = 'Species') \n\n\n\n\n\n\n\n\nBut as you see, it gets a bit hard to orient in the plot. There are some NA values in the sex column, which would be better removed so that they do not add a mess to the plot. And what about splitting the plot into three smaller plots, one for each species? This is where facetting comes into play.\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, fill = sex, shape = species)) +\n  geom_point() + \n  geom_smooth(aes(colour = sex), method = 'lm', show.legend = F) + \n  scale_shape_manual(values = c(21, 22, 24)) + \n  labs(x = 'Bill length (mm)', y = 'Bill depth (mm)', fill = 'Sex', shape = 'Species') + \n  facet_wrap(~species)+\n  theme_bw()\n\n\n\n\n\n\n\n\nMuch better, but do we really need the different shapes for different species if we have them now in different facets? It would be better to add shape differentiation to the sex variable as not everyone is able to distinguish colours. It might also help in the legend, where we now have just black dots for both levels.\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, fill = sex, shape = sex)) +\n  geom_point() + \n  geom_smooth(aes(colour = sex), method = 'lm', show.legend = F) + \n  scale_shape_manual(values = c(21, 22, 24)) + \n  labs(x = 'Bill length (mm)', y = 'Bill depth (mm)', fill = 'Sex', shape = 'Sex') + \n  facet_wrap(~species)+\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can now clearly see that for Ad√©lie penguins, there is a positive relationship between bill length and bill depth for females, but not for males. On the other hand, for Chinstrap penguins, the relationship is stronger for males than for females.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "6 Advanced data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/6_advanced_visualisation.html#data-argument",
    "href": "DataManipulationVisualisation/6_advanced_visualisation.html#data-argument",
    "title": "6 Advanced Visualisation",
    "section": "6.2 Data argument",
    "text": "6.2 Data argument\nTill now, we have worked just with one data frame for the whole plot. You might remember that it is possible to place aesthetic mappings (aes()) either in the ggplot() call, and then it works for the whole plot, or in a geom function, which then overwrites the global mappings for that layer only. The same is possible for the data argument. We can define a different dataset for a certain layer to add, e.g., points from another dataset or highlight a subset of the data.\nAs an example, we will draw a scatterplot of penguin body mass vs flipper length, where we highlight penguins from the Dream island with bigger red points:\n\npenguins |&gt; \n  ggplot(aes(body_mass_g, flipper_length_mm))+\n  geom_point()+\n  geom_point(data = penguins |&gt; filter(island == 'Dream'), colour = 'red', size = 3)+\n  theme_bw()+\n  labs(x = 'Body mass (g)', y = 'Flipper length (mm)')\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNote that we added specifications of the point appearance of the highlighted point in the geom_point() function outside the aes(). This means the characteristics are fixed for that layer and do not change according to the data. All the points of that layer will always be red and of size 3.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "6 Advanced data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/6_advanced_visualisation.html#scales",
    "href": "DataManipulationVisualisation/6_advanced_visualisation.html#scales",
    "title": "6 Advanced Visualisation",
    "section": "6.3 Scales",
    "text": "6.3 Scales\nScale functions always follow the pattern scale_{aesthetic}_{type}. We already used scale_shape_manual() to manually rewrite the default shapes used in the plot. We can use scales to modify values, limits, breaks or labels of any aesthetics in our plot, typically colour, fill, and shape. To define desired values on your own, you can use manual scale definition, but there are many other types, e.g.¬†continuous (useful, e.g., for defining labels for continuous variables), discrete (e.g.¬†labels for discrete variables), gradient (e.g.¬†for defining colour gradient for continuous variables). scale_x_{type} and scale_y_{type} are useful to define axis limits, ticks and labels.\nWe will use the example of penguin body mass vs.¬†flipper length and modify different scales of this plot. First of all, we will show with different colours on which island the penguins were measured. To change the default colours, we can define our own colours using scale_fill_manual() and the values argument inside, similarly to what we did for the shape before. But we can also use a predefined colour scale, e.g.¬†from colour brewer using scale_fill_brewer(). We can also modify the labels in the legend by using the argument labels. Let‚Äôs say we want to add the word ‚ÄòIsland‚Äô to each label:\n\npenguins |&gt; \n  ggplot(aes(body_mass_g, flipper_length_mm, fill = island))+\n  geom_point(pch = 21)+\n  scale_fill_brewer(type = 'qual', palette = 7, labels = c('Dream' = 'Dream Island', 'Biscoe' = 'Biscoe Island', 'Torgersen' = 'Torgersen Island'))+\n  theme_bw()+\n  labs(x = 'Body mass (g)', y = 'Flipper length (mm)', fill = 'Island')\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWe used type = 'qual' inside scale_color_brewer() to use colours appropriate for discrete values. You can experiment with many more such colour scales that are already available.\nInstead of colouring the points according to the island, we can also use colours to show a numerical variable, e.g.¬†year when the measurement was taken:\n\npenguins |&gt; \n  ggplot(aes(body_mass_g, flipper_length_mm, fill = year))+\n  geom_point(pch = 21)+\n  theme_bw()+\n  labs(x = 'Body mass (g)', y = 'Flipper length (mm)', fill = 'Year')\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNote that the plot automatically chooses a continuous colour scale instead of the discrete one before, and the legend now shows a range from the lowest to the highest value. But for the year, it doesn‚Äôt really make sense to show decimals. We can modify this using scale_fill_continuous():\n\npenguins |&gt; \n  ggplot(aes(body_mass_g, flipper_length_mm, fill = year))+\n  geom_point(pch = 21)+\n  scale_fill_continuous(breaks = c(2007, 2008, 2009))+\n  theme_bw()+\n  labs(x = 'Body mass (g)', y = 'Flipper length (mm)', fill = 'Year')\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nScales are also useful to set limits, breaks or labels on the plot axes. For example, we might want to zoom only to the penguins with body mass between 3000 and 5000 g:\n\npenguins |&gt; \n  ggplot(aes(body_mass_g, flipper_length_mm, fill = year))+\n  geom_point(pch = 21)+\n  scale_fill_continuous(breaks = c(2007, 2008, 2009))+\n  scale_x_continuous(limits = c(3000, 5000))+\n  theme_bw()+\n  labs(x = 'Body mass (g)', y = 'Flipper length (mm)', fill = 'Year')\n\nWarning: Removed 72 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNote that when we do this, we get a warning message, indicating how many points were not displayed because they are outside the defined range. That‚Äôs just to prevent us from accidentally missing them.\nIt is even possible to transform the axis using the transform argument or shortcuts for commonly used transformations, e.g.¬†scale_x_log10().",
    "crumbs": [
      "Data Manipulation and Visualization",
      "6 Advanced data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/6_advanced_visualisation.html#legend-modifications",
    "href": "DataManipulationVisualisation/6_advanced_visualisation.html#legend-modifications",
    "title": "6 Advanced Visualisation",
    "section": "6.4 Legend modifications",
    "text": "6.4 Legend modifications\nIn all the plots we made so far, the legend was by default placed on the right side next to the plot. Sometimes it is helpful to move it somewhere else, for example, due to space constraints. Legend position might be modified inside the theme() function. We can move it to the bottom of the plot:\n\npenguins |&gt; \n  ggplot(aes(body_mass_g, flipper_length_mm, fill = island))+\n  geom_point(pch = 21)+\n  scale_fill_brewer(type = 'qual', palette = 7, labels = c('Dream' = 'Dream Island', 'Biscoe' = 'Biscoe Island', 'Torgersen' = 'Torgersen Island'))+\n  theme_bw()+\n  theme(legend.position = 'bottom')+\n  labs(x = 'Body mass (g)', y = 'Flipper length (mm)', fill = 'Island')\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nSometimes, there is a space inside the plot, so it is possible to place the legend there and reduce the image size. In this case, we have to specify two arguments, legend.position() and legend.justification(). The values should indicate coordinates on the two axes and have values of 0-1, where 0 means the beginning of the axis and 1 the end. For example, 0, 0 means the bottom left corner of the plot, 1, 1 the top right corner.\n\npenguins |&gt; \n  ggplot(aes(body_mass_g, flipper_length_mm, fill = island))+\n  geom_point(pch = 21)+\n  scale_fill_brewer(type = 'qual', palette = 7, labels = c('Dream' = 'Dream Island', 'Biscoe' = 'Biscoe Island', 'Torgersen' = 'Torgersen Island'))+\n  theme_bw()+\n  theme(legend.position = c(1, 0), legend.justification = c(1, 0))+\n  labs(x = 'Body mass (g)', y = 'Flipper length (mm)', fill = 'Island')\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\n‚Ñπ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nTo remove the legend completely, set legend.position = 'none'.\nThe theme() function allows us to modify many more plot elements. We can remove any plot component by setting the argument for it to element_blank(), modify the text size, label angle, ticks length, background grid colour and many more. See the documentation for more details.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "6 Advanced data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/6_advanced_visualisation.html#composing-plots-together",
    "href": "DataManipulationVisualisation/6_advanced_visualisation.html#composing-plots-together",
    "title": "6 Advanced Visualisation",
    "section": "6.5 Composing plots together",
    "text": "6.5 Composing plots together\nSometimes it is useful to combine multiple plots in one figure with multiple panels. This might be easily done using the patchwork package.\n\nlibrary(patchwork)\n\n(Please place this line at the top of your script.)\nLet‚Äôs say we want to make one figure showing the relationship between the penguin bill length and bill depth for the three penguin species and a boxplot showing the distribution of body mass for individual species next to each other.\nWe will first create these two plots and save them to an object:\n\np1 &lt;- penguins |&gt; \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, fill = species, shape = species)) +\n  geom_point() + \n  geom_smooth(aes(colour = species), method = 'lm', show.legend = F) + \n  scale_shape_manual(values = c(21, 22, 24)) + \n  labs(x = 'Bill length (mm)', y = 'Bill depth (mm)', fill = 'Species', shape = 'Species') + \n  theme_bw()\n\np2 &lt;- ggplot(penguins, aes(x = species, y = body_mass_g, fill = species)) +\n  geom_boxplot() + \n  labs(y = 'Body mass (g)', fill = 'Species') + \n  theme_bw() + \n  theme(axis.title.x = element_blank())\n\nAnd then combine the two plots together:\n\np1 + p2\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nSo easy it is. And we can play more with the plot layout. Some useful functionalities of the patchwork package are that you can add annotations to the plots to identify individual panels:\n\np1 + p2 + plot_annotation(tag_levels = 'a')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nOr collect all legends of the subplots and place them in one place:\n\np1 + p2 + plot_layout(guides = 'collect')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).",
    "crumbs": [
      "Data Manipulation and Visualization",
      "6 Advanced data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/6_advanced_visualisation.html#useful-extensions",
    "href": "DataManipulationVisualisation/6_advanced_visualisation.html#useful-extensions",
    "title": "6 Advanced Visualisation",
    "section": "6.6 Useful extensions",
    "text": "6.6 Useful extensions\nIt is possible to do almost everything you would imagine using ggplot2 and its extensions. We do not have time to cover all of that during this semester, but you are very welcome to experiment and explore this world on your own.\nJust a few tips for packages we personally find very useful for our work:\n\nggpubr to make publication-ready plots - some easy-to-use functions for creating and customising ggplot plots\nggeffects to calculate model predictions and plot them (will be replaced by modelbased, but the functionality shouldn‚Äôt be lost)\ngordi a ggplot-based package for making ordination plots, developed in our group (coming soon üòâ)\nggnewscale to use multiple colour or fill scales in the same plot, especially useful for maps\nshiny for creating web apps from R",
    "crumbs": [
      "Data Manipulation and Visualization",
      "6 Advanced data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/6_advanced_visualisation.html#exercises",
    "href": "DataManipulationVisualisation/6_advanced_visualisation.html#exercises",
    "title": "6 Advanced Visualisation",
    "section": "6.7 Exercises",
    "text": "6.7 Exercises\n\nfacet_wrap() facets the plot according to one variable, look in the documentation, what the related function facet_grid() does and use it to make a plot of penguin bill length and bill depth faceted by species and island.\nUse the gapminder dataset, from the gapminder package, which provides values for life expectancy, GDP per capita, and population size for each country of the world. Visualise the relationship between GDP per capita (on a log scale) and life expectancy in 2007. Highlight the Czech Republic and Slovakia with different colours. Place the legend in the top left corner of the plot. * Make the size of the points proportional to the country population size.\nCreate a plot showing the development of life expectancy in the Czech Republic and Slovakia over time.\nCombine the two plots using p1 / p2. What is the difference compared to p1 + p2? Add annotations ‚ÄòA‚Äô and ‚ÄòB‚Äô to the panels. * Modify the legend so that there is only one legend with coloured points at the bottom.\nUse the dataset Axmanova-Forest-understory-diversity-analyses.xlsx and create four boxplots comparing Ellenberg-type indicator values in different forest types. Combine all four plots together and add annotations to individual panels. Do not show any legend and remove the title for the x-axis. * Turn the axis tick labels by 45¬∞.\nplot xx\nplot yy\nrecreate a plot\nSave all plots you created so far to the plots folder.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "6 Advanced data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/6_advanced_visualisation.html#further-reading",
    "href": "DataManipulationVisualisation/6_advanced_visualisation.html#further-reading",
    "title": "6 Advanced Visualisation",
    "section": "6.8 Further reading",
    "text": "6.8 Further reading\nggplot2 vignette: https://ggplot2.tidyverse.org\nR 4 Data Science: https://r4ds.hadley.nz/visualize.html\nCheatsheet: https://rstudio.github.io/cheatsheets/html/data-visualization.html\nAesthetics specifications vignette: https://ggplot2.tidyverse.org/articles/ggplot2-specs.html\nggplot2: Elegant Graphics for Data Analysis (3e): https://ggplot2-book.org\nR Graphics Cookbook: https://r-graphics.org\npatchwork vignette: https://patchwork.data-imaginist.com/index.html\nggplot Extensions: https://exts.ggplot2.tidyverse.org/gallery\nMastering Shiny: https://mastering-shiny.org\nTutorial for effective visual science communication: https://ascpt.onlinelibrary.wiley.com/doi/full/10.1002/psp4.12455\nGraphics principles cheatsheet: https://github.com/GraphicsPrinciples/CheatSheet/blob/master/NVSCheatSheet.pdf",
    "crumbs": [
      "Data Manipulation and Visualization",
      "6 Advanced data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/2_data_manipulation.html",
    "href": "DataManipulationVisualisation/2_data_manipulation.html",
    "title": "2 Data Manipulation",
    "section": "",
    "text": "select, filter, mutate, arrange, slice data export (write_csv)",
    "crumbs": [
      "Data Manipulation and Visualization",
      "2 Data manipulation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/12_github.html",
    "href": "DataManipulationVisualisation/12_github.html",
    "title": "12 GitHub",
    "section": "",
    "text": "version control and GitHub\neasy: how to find, download code from someone without an account (examples - maps course, published codes for articles)\nbut much more is possible when you create your own account:\ninstall git\ncreate your own GitHub account\nsetup connection with RStudio\ncreate your first repository (e.g.¬†for your scripts from this course)\nsettings - private repositories, colaborators\ncode, readme, issues etc.\ncommit, push, pull\nbranches, pull request\nmerge conflicts\npublication in a long-term repository - connection with Zenodo\nGitHub pages - our study materials, personal webpages (add examples)",
    "crumbs": [
      "Data Manipulation and Visualization",
      "12 GitHub"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/12_github.html#further-reading",
    "href": "DataManipulationVisualisation/12_github.html#further-reading",
    "title": "12 GitHub",
    "section": "Further reading",
    "text": "Further reading\nHappy Git and GitHub for the useR: https://happygitwithr.com",
    "crumbs": [
      "Data Manipulation and Visualization",
      "12 GitHub"
    ]
  },
  {
    "objectID": "CommunityEcology/community_ecology.html",
    "href": "CommunityEcology/community_ecology.html",
    "title": "Data Analysis in Community Ecology",
    "section": "",
    "text": "Cookbook might be moved here",
    "crumbs": [
      "Community Ecology"
    ]
  },
  {
    "objectID": "AIinTeaching/ai_in_teaching.html",
    "href": "AIinTeaching/ai_in_teaching.html",
    "title": "AI in Data Analysis",
    "section": "",
    "text": "How to use AI in data analysis?",
    "crumbs": [
      "AI in Data Analysis"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/1_introduction.html",
    "href": "DataManipulationVisualisation/1_introduction.html",
    "title": "1 Introduction",
    "section": "",
    "text": "In this chapter, we will train how to get ready for analyses in R. Preparing the project, starting a script, importing data and their first exploration. We will follow the rules for preparing reproducible, reportable, clean and tidy workflow and scripts.\nYou already know that R is a programming language and environment for statistical analysis and data visualisation. R is free and open-source, available from the CRAN directory. R is extended by a large number of software packages, which contain reusable code, documentation, and sample data. In this course, we will focus in the first place on the tidyverse collection of packages, which are designed for everyday data handling and visualisation (see more here).\nWe will work with R using the interface called RStudio IDE, in short RStudio, which is an integrated development environment for R and can be downloaded here.\nTO DO: install R, RStudio and tidyverse package. Having trouble and need advice? Try further reading section at the end of this chapter or come and ask before the first lesson.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "1 Introduction"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/1_introduction.html#introducing-tidyverse",
    "href": "DataManipulationVisualisation/1_introduction.html#introducing-tidyverse",
    "title": "1 Introduction",
    "section": "1.1. Introducing Tidyverse",
    "text": "1.1. Introducing Tidyverse\n\n\n\n\n\nTidyverse is a collection of R packages for transforming and visualizing data, which share an underlying philosophy (tidy data, tibbles, %&gt;%) and common interface. When you install the tidyverse, you get all the core packages at once, namely\n\nreadr for data importing\n\ndplyr with tools for data manipulation (e.g.¬†select, filter, arrange, mutate‚Ä¶)\ntidyr with functions that help you get to tidy data and transform their format (e.g.pivot)\ntibble introducing simple dataframes called tibbles\nggplot2 package for data visualisation\nstringrfor working with strings, matching defined patterns, clean unwanted parts\nforcats which enables easier work with factors\nlubridatehelping to work with date-times\npurr which offers complete and consistent set of tools for working with functions and vectors, introduces map function instead of complicated loops\n\nIn addition you get automatically installed also several more packages, which share the same approach, although developed later or by someone else, for example - readxl elegant direct import from Excel files - magrittrpackage where the pipe was originally introduced, including double-sided pipe\nFind more about tidyverse here or check cheatsheets and vignettes for individual packages.\nRemember, that all the core packages are activated within the tidyverse library\n\nlibrary(tidyverse)\n\nwhile for the extra ones you have to use an extra call\n\nlibrary(readxl)\n\n\n1.1.1 Tidy data\nData that are easy to handle and analyse. \nFind more in the R for data science book https://r4ds.hadley.nz/\n\n\n1.1.2 Tibbles\nTibbles are new, updated versions of base-R data frames. They are designed to work better with other tidyverse packages. In contrast to data frames, tibbles never convert the type of the inputs (e.g.¬†strings to factors), they never change the names of variables, and they never create row names. Example:\n\ndata &lt;- read_excel(\"data/forest_understory/Axmanova-Forest-understory-diversity-analyses.xlsx\")\ntibble (data)\n\n# A tibble: 65 √ó 22\n   PlotID ForestType ForestTypeName      Herbs Juveniles CoverE1 Biomass\n    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1      1          2 oak hornbeam forest    26        12      20    12.8\n 2      2          1 oak forest             13         3      25     9.9\n 3      3          1 oak forest             14         1      25    15.2\n 4      4          1 oak forest             15         5      30    16  \n 5      5          1 oak forest             13         1      35    20.7\n 6      6          1 oak forest             16         3      60    46.4\n 7      7          1 oak forest             17         5      70    49.2\n 8      8          2 oak hornbeam forest    21         1      70    48.7\n 9      9          2 oak hornbeam forest    15         4      15    13.8\n10     10          1 oak forest             14         4      75    79.1\n# ‚Ñπ 55 more rows\n# ‚Ñπ 15 more variables: Soil_depth_categ &lt;dbl&gt;, pH_KCl &lt;dbl&gt;, Slope &lt;dbl&gt;,\n#   Altitude &lt;dbl&gt;, Canopy_E3 &lt;dbl&gt;, Radiation &lt;dbl&gt;, Heat &lt;dbl&gt;,\n#   TransDir &lt;dbl&gt;, TransDif &lt;dbl&gt;, TransTot &lt;dbl&gt;, EIV_light &lt;dbl&gt;,\n#   EIV_moisture &lt;dbl&gt;, EIV_soilreaction &lt;dbl&gt;, EIV_nutrients &lt;dbl&gt;, TWI &lt;dbl&gt;\n\n\n\n\n1.1.3 Pipes %&gt;%\nThe Tidyverse tools use a pipe: %&gt;% or |&gt; The pipe allows the output of a previous command to be used as input to another command instead of using nested functions. It means, pipe binds individual steps into a sequence and it reads from left to right. In base R the logic of reading is from inside out and you have to save all the steps separately.\nSee this example of the same steps with different approaches&gt;\nBase R method\n\ndata &lt;- read_excel(\"data/forest_understory/Axmanova-Forest-understory-diversity-analyses.xlsx\")\n# 1. Create new variable in the data\ndata$Productivity &lt;- ifelse(data$Biomass &lt; 60, \"low\", \"high\")\n\n# 2. Select only some columns, save as new dataframe\ndf &lt;- data[, c(\"PlotID\", \"ForestTypeName\", \"Productivity\", \"pH_KCl\")]\n\n# 3. Order by soil pH (descending)\ndf &lt;- df[order(df$pH_KCl, decreasing = TRUE), ]\n\n# 4. Keep only the first 15 rows with highest pH\ndf_top20 &lt;- df[1:15, ]\n\n# 5. Print the resulting subset to see which forest types grow in the high pH soils and if they have rather low or high productivity\ndf_top20\n\n# A tibble: 15 √ó 4\n   PlotID ForestTypeName      Productivity pH_KCl\n    &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;         &lt;dbl&gt;\n 1    104 alluvial forest     high           7.14\n 2    103 alluvial forest     high           7.13\n 3    128 ravine forest       high           7.03\n 4    111 alluvial forest     high           7.01\n 5    114 ravine forest       high           6.93\n 6    123 ravine forest       low            6.91\n 7    105 ravine forest       high           6.78\n 8    122 ravine forest       high           6.68\n 9    101 alluvial forest     high           6.67\n10    119 oak hornbeam forest low            6.63\n11    113 alluvial forest     high           6.61\n12    120 oak hornbeam forest high           6.42\n13    115 ravine forest       low            6.03\n14    110 alluvial forest     high           5.82\n15    121 oak hornbeam forest high           5.77\n\n\nPiping (the same steps, but just in one line)\n\ndata &lt;- read_excel(\"data/forest_understory/Axmanova-Forest-understory-diversity-analyses.xlsx\") %&gt;%\n  mutate(Productivity = ifelse(Biomass &lt; 100, \"low\", \"high\")) %&gt;%\n  select(PlotID, ForestTypeName, Productivity, pH_KCl) %&gt;%\n  arrange(desc(pH_KCl)) %&gt;%\n  slice_head(n = 15) %&gt;%\n  print()\n\n# A tibble: 15 √ó 4\n   PlotID ForestTypeName      Productivity pH_KCl\n    &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;         &lt;dbl&gt;\n 1    104 alluvial forest     high           7.14\n 2    103 alluvial forest     high           7.13\n 3    128 ravine forest       high           7.03\n 4    111 alluvial forest     low            7.01\n 5    114 ravine forest       low            6.93\n 6    123 ravine forest       low            6.91\n 7    105 ravine forest       low            6.78\n 8    122 ravine forest       high           6.68\n 9    101 alluvial forest     low            6.67\n10    119 oak hornbeam forest low            6.63\n11    113 alluvial forest     low            6.61\n12    120 oak hornbeam forest low            6.42\n13    115 ravine forest       low            6.03\n14    110 alluvial forest     high           5.82\n15    121 oak hornbeam forest low            5.77\n\n\nNote: It is even possible to overwrite original dataset with an assignment pipe %&lt;&gt;% included in magrittr package. We will try to avoid this in our lessons, as it cannot be undone.\nTip: Insert a pipe by ctrl+shift+M",
    "crumbs": [
      "Data Manipulation and Visualization",
      "1 Introduction"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/1_introduction.html#effective-and-reproducible-workflow",
    "href": "DataManipulationVisualisation/1_introduction.html#effective-and-reproducible-workflow",
    "title": "1 Introduction",
    "section": "1.2. Effective and reproducible workflow",
    "text": "1.2. Effective and reproducible workflow\nThere are several rules to make your workflow effective and reproducible after some time or by other people.\n\n1.2.1 Projects\nIf you start your work by setting the working directory, the reproducibility by someone else is very limited (see more here). Good habit is to organize each data analysis into a project: a folder on your computer that holds all the files relevant to that particular piece of work.\nR Studio easily enables creating projects and switching between them (either through File-Open/New/Recent Project or by clicking on the upper right corner icon for projects). \nTip: get used to creating the same subfolders in each of your project: data, scripts, results, maps, backup etc. to further organise the project structure.\n\n\n1.2.2 Scripts\nlibraries - list all the libraries your code need at the beginning of the script\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nremarks\n- add notes to your scripts, you will be grateful later\n- change the text to non-active (marked with hash tags #) ctrl + shift + C\nseparate scripts or sections\n- insert named section using ctrl + shift + R\n- or divide the code by ####\n- fold all sections with Alt + O\n- unfold all with Shift + Alt + O\nnames of variables\n- should be short and easy to handle, without spaces, strange symbols Simple variable names will save you really so much time and parentheses !\nSee this example\n\ndata &lt;- read_csv(\"data/messy_data/Example0.csv\")\nnames(data)\n\n[1] \"Relev√© number\"                   \"Taxon\"                          \n[3] \"Vegetation layer\"                \"Cover %\"                        \n[5] \"Braun-Blanquet Scale (New) Code\"\n\n\nYou can rename strange names one by one. First use the new name and put the old one on the right like here.\n\ndata %&gt;% rename (Releve = \"Relev√© number\")\n\n# A tibble: 51 √ó 5\n   Releve Taxon              `Vegetation layer` `Cover %` Braun-Blanquet Scale‚Ä¶¬π\n    &lt;dbl&gt; &lt;chr&gt;                           &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                 \n 1 435469 Ribes uva-crispa                    0         2 +                     \n 2 435469 Ulmus minor                         0         3 1                     \n 3 435469 Crataegus monogyn‚Ä¶                  0         2 +                     \n 4 435469 Rubus caesius                       0        13 a                     \n 5 435469 Prunus padus ssp.‚Ä¶                  0         3 1                     \n 6 435469 Populus alba                        0        13 a                     \n 7 435469 Fraxinus excelsior                  0        68 4                     \n 8 435469 Arctium lappa                       6         1 r                     \n 9 435469 Adoxa moschatelli‚Ä¶                  6         2 +                     \n10 435469 Aegopodium podagr‚Ä¶                  6        13 a                     \n# ‚Ñπ 41 more rows\n# ‚Ñπ abbreviated name: ¬π‚Äã`Braun-Blanquet Scale (New) Code`\n\n\nOr you can change all difficult patterns at once, using RegEx Regular expressions. Import the example once again.\nYou identify the pattern on left, starting with two backslashes and define the outcome on right side. Be sure to keep the logic in your sequence - what is first and what last, as it really changes the patterns one by one, as they are listed.\n\ndata &lt;- read_csv(\"data/messy_data/Example0.csv\")\nnames(data)\n\n[1] \"Relev√© number\"                   \"Taxon\"                          \n[3] \"Vegetation layer\"                \"Cover %\"                        \n[5] \"Braun-Blanquet Scale (New) Code\"\n\ndata %&gt;%\n  rename_all(~ str_replace_all(., c(\n    \"\\\\.\" = \"\",     # remove dots in the variable names\n    \"\\\\√©\" = \"e\",    # replace √© by e\n    \"\\\\%\" = \"perc\", # remove symbol % and change it to perc\n    \"\\\\(\" = \"\",     # remove brackets\n    \"\\\\)\" = \"\",     # remove brackets\n    \"\\\\/\" = \"\",     # remove slash\n    \"\\\\?\" = \"\",     # remove questionmark\n    \"\\\\s\" = \".\")))   # remove spaces\n\n# A tibble: 51 √ó 5\n   Releve.number Taxon        Vegetation.layer Cover.perc Braun-Blanquet.Scale‚Ä¶¬π\n           &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                 \n 1        435469 Ribes uva-c‚Ä¶                0          2 +                     \n 2        435469 Ulmus minor                 0          3 1                     \n 3        435469 Crataegus m‚Ä¶                0          2 +                     \n 4        435469 Rubus caesi‚Ä¶                0         13 a                     \n 5        435469 Prunus padu‚Ä¶                0          3 1                     \n 6        435469 Populus alba                0         13 a                     \n 7        435469 Fraxinus ex‚Ä¶                0         68 4                     \n 8        435469 Arctium lap‚Ä¶                6          1 r                     \n 9        435469 Adoxa mosch‚Ä¶                6          2 +                     \n10        435469 Aegopodium ‚Ä¶                6         13 a                     \n# ‚Ñπ 41 more rows\n# ‚Ñπ abbreviated name: ¬π‚Äã`Braun-Blanquet.Scale.New.Code`\n\n\nNow check the names again. Did it work?\n- Tip*: use the function clean_names from package janitor\nNote that in the examples above you are not really rewriting the data you have imported. Here the ‚Äúdata %&gt;%‚Äù means, that you are just trying how it would look like if you apply the following steps to data. To really change it you would have to assign your result into any new dataset. - - data2&lt;- data1 %&gt;% ‚Ä¶ #defining first the new dataset - data&lt;-data %&gt;% ‚Ä¶ #rewriting the dataset (the same would be done by data %&lt;&gt;% data) - data1 %&gt;% ‚Ä¶..-&gt;data2 #making/testing all the steps and assigning it to new dataset as the last step This might sound troublesome, but it is actually very helpful. You can try all the steps and when you are happy with the code, you can put everything into one pipe line from import of the data to export of the result.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "1 Introduction"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/1_introduction.html#data-import",
    "href": "DataManipulationVisualisation/1_introduction.html#data-import",
    "title": "1 Introduction",
    "section": "1.3 Data import",
    "text": "1.3 Data import\nWe will train how to import data with Tidyverse, which means readr or readxl in case of Excel files (see cheatsheet)\nWhat is useful is to check which files are stored in the folders we have. Here we list all files in the working=project directory\n\nlist.files() \n\n [1] \"1_introduction.qmd\"                  \"1_introduction.rmarkdown\"           \n [3] \"11_database_to_plot.html\"            \"11_database_to_plot.qmd\"            \n [5] \"12_github.html\"                      \"12_github.qmd\"                      \n [7] \"2_data_manipulation.qmd\"             \"3_data_visualisation.qmd\"           \n [9] \"4_wide_vs_long.qmd\"                  \"5_join_functions.qmd\"               \n[11] \"6_advanced_visualisation.qmd\"        \"7_8_automatisation.qmd\"             \n[13] \"9_10_maps.qmd\"                       \"data\"                               \n[15] \"data_manipulation_visualisation.qmd\" \"exercisesIA\"                        \n[17] \"images\"                              \"plots\"                              \n[19] \"scripts\"                            \n\n\nOr we can dive deeper in the hierarchy and check content of data folder, or specific subfolder\n\nlist.files(\"data\") \n\n[1] \"acidophilous_grasslands\" \"basiphilous_grasslands\" \n[3] \"forest_understory\"       \"frozen_fauna\"           \n[5] \"gapminder\"               \"gapminder_clean\"        \n[7] \"gapminder_continent\"     \"messy_data\"             \n[9] \"sands\"                  \n\nlist.files(\"data/forest_understory\")\n\n[1] \"Axmanova-Forest-env.xlsx\"                             \n[2] \"Axmanova-Forest-spe.xlsx\"                             \n[3] \"Axmanova-Forest-understory-diversity-analyses.xlsx\"   \n[4] \"Axmanova-Forest-understory-diversity-merged-long.xlsx\"\n[5] \"readme.txt\"                                           \n[6] \"traits.xlsx\"                                          \n\n\nLet‚Äôs select one of the files and import it into our working environment. Depending on the type of file I have to select the right approach. Here it is an Excel file, so I can use function read_excel. Check the cheatsheet for more tips.\n\ndata &lt;- read_excel(\"data/forest_understory/Axmanova-Forest-understory-diversity-analyses.xlsx\")\n\nWe imported the data and here are a few tips how to check the structure\nFirst is the tibble, which actually appears automatically after any import using tidyverse approach - note that only ten rows and several variables are shown, if there are too many, rest is listed below.\n\ntibble(data)\n\n# A tibble: 65 √ó 22\n   PlotID ForestType ForestTypeName      Herbs Juveniles CoverE1 Biomass\n    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1      1          2 oak hornbeam forest    26        12      20    12.8\n 2      2          1 oak forest             13         3      25     9.9\n 3      3          1 oak forest             14         1      25    15.2\n 4      4          1 oak forest             15         5      30    16  \n 5      5          1 oak forest             13         1      35    20.7\n 6      6          1 oak forest             16         3      60    46.4\n 7      7          1 oak forest             17         5      70    49.2\n 8      8          2 oak hornbeam forest    21         1      70    48.7\n 9      9          2 oak hornbeam forest    15         4      15    13.8\n10     10          1 oak forest             14         4      75    79.1\n# ‚Ñπ 55 more rows\n# ‚Ñπ 15 more variables: Soil_depth_categ &lt;dbl&gt;, pH_KCl &lt;dbl&gt;, Slope &lt;dbl&gt;,\n#   Altitude &lt;dbl&gt;, Canopy_E3 &lt;dbl&gt;, Radiation &lt;dbl&gt;, Heat &lt;dbl&gt;,\n#   TransDir &lt;dbl&gt;, TransDif &lt;dbl&gt;, TransTot &lt;dbl&gt;, EIV_light &lt;dbl&gt;,\n#   EIV_moisture &lt;dbl&gt;, EIV_soilreaction &lt;dbl&gt;, EIV_nutrients &lt;dbl&gt;, TWI &lt;dbl&gt;\n\n\nalternative way is to use glimpse, where the variables are listed below each other, showing the first 15 values\n\nglimpse(data)\n\nRows: 65\nColumns: 22\n$ PlotID           &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 18, 28, 29‚Ä¶\n$ ForestType       &lt;dbl&gt; 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2,‚Ä¶\n$ ForestTypeName   &lt;chr&gt; \"oak hornbeam forest\", \"oak forest\", \"oak forest\", \"o‚Ä¶\n$ Herbs            &lt;dbl&gt; 26, 13, 14, 15, 13, 16, 17, 21, 15, 14, 12, 30, 24, 1‚Ä¶\n$ Juveniles        &lt;dbl&gt; 12, 3, 1, 5, 1, 3, 5, 1, 4, 4, 4, 3, 7, 3, 1, 2, 2, 7‚Ä¶\n$ CoverE1          &lt;dbl&gt; 20, 25, 25, 30, 35, 60, 70, 70, 15, 75, 8, 30, 60, 85‚Ä¶\n$ Biomass          &lt;dbl&gt; 12.8, 9.9, 15.2, 16.0, 20.7, 46.4, 49.2, 48.7, 13.8, ‚Ä¶\n$ Soil_depth_categ &lt;dbl&gt; 5.0, 4.5, 3.0, 3.0, 3.0, 6.0, 7.0, 5.0, 3.5, 5.0, 2.0‚Ä¶\n$ pH_KCl           &lt;dbl&gt; 5.28, 3.24, 4.01, 3.77, 3.50, 3.80, 3.48, 3.68, 4.24,‚Ä¶\n$ Slope            &lt;dbl&gt; 4, 24, 13, 21, 0, 10, 6, 0, 38, 13, 29, 47, 33, 24, 0‚Ä¶\n$ Altitude         &lt;dbl&gt; 412, 458, 414, 379, 374, 380, 373, 390, 255, 340, 368‚Ä¶\n$ Canopy_E3        &lt;dbl&gt; 80, 80, 80, 75, 70, 65, 65, 85, 80, 70, 85, 60, 75, 7‚Ä¶\n$ Radiation        &lt;dbl&gt; 0.8813, 0.9329, 0.9161, 0.9305, 0.8691, 0.9178, 0.829‚Ä¶\n$ Heat             &lt;dbl&gt; 0.8575, 0.8138, 0.8503, 0.9477, 0.8691, 0.8834, 0.803‚Ä¶\n$ TransDir         &lt;dbl&gt; 3.72, 4.05, 4.38, 3.48, 3.73, 3.59, 4.49, 3.97, 3.61,‚Ä¶\n$ TransDif         &lt;dbl&gt; 2.83, 2.83, 2.94, 2.96, 3.15, 3.40, 2.87, 2.99, 2.92,‚Ä¶\n$ TransTot         &lt;dbl&gt; 6.55, 6.88, 7.31, 6.44, 6.88, 6.99, 7.36, 6.96, 6.53,‚Ä¶\n$ EIV_light        &lt;dbl&gt; 5.00, 4.71, 4.36, 5.26, 6.14, 6.19, 6.19, 5.29, 5.47,‚Ä¶\n$ EIV_moisture     &lt;dbl&gt; 4.38, 4.64, 4.70, 4.38, 4.00, 4.35, 4.25, 4.60, 4.36,‚Ä¶\n$ EIV_soilreaction &lt;dbl&gt; 6.68, 4.67, 4.80, 5.53, 5.33, 6.75, 6.09, 5.07, 5.46,‚Ä¶\n$ EIV_nutrients    &lt;dbl&gt; 4.31, 3.69, 3.55, 3.56, 3.46, 5.06, 4.33, 4.12, 3.50,‚Ä¶\n$ TWI              &lt;dbl&gt; 3.353962, 2.419177, 2.159580, 1.651170, 4.741780, 2.4‚Ä¶\n\n\nif you forget the names of variables or you want to copy them and store in your script, use simple names\n\nnames(data)\n\n [1] \"PlotID\"           \"ForestType\"       \"ForestTypeName\"   \"Herbs\"           \n [5] \"Juveniles\"        \"CoverE1\"          \"Biomass\"          \"Soil_depth_categ\"\n [9] \"pH_KCl\"           \"Slope\"            \"Altitude\"         \"Canopy_E3\"       \n[13] \"Radiation\"        \"Heat\"             \"TransDir\"         \"TransDif\"        \n[17] \"TransTot\"         \"EIV_light\"        \"EIV_moisture\"     \"EIV_soilreaction\"\n[21] \"EIV_nutrients\"    \"TWI\"             \n\n\nQuite useful baseR approach function is table, which shows the counts per categories of selected variable. In tidyverse it will need more steps to be done, but we will get there next time‚Ä¶\n\ntable(data$ForestTypeName)\n\n\n    alluvial forest          oak forest oak hornbeam forest       ravine forest \n                 11                  16                  28                  10 \n\n\nOf course, you can also view() the data or click on it in the list in the Files to open it, however, this is not recommended with huge tables, as the previews are rather memory demanding.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "1 Introduction"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/1_introduction.html#where-to-find-help",
    "href": "DataManipulationVisualisation/1_introduction.html#where-to-find-help",
    "title": "1 Introduction",
    "section": "1.4 Where to find help",
    "text": "1.4 Where to find help\nMotto: Majority of the problems in R can be solved if you know how to ask and where.\nKnowing that I am lost in ‚ÄúRegular expressions‚Äù already helps to ask more specifically.\n\nR studio help Try intergrated help in R studio, where you can find links to selected manuals, cheat sheets. It is the place where you can also find Keyboard shortcuts help to find out which combinations do what. e.g.¬†shift+ctrl+m\nCheatsheets - the most important features of a given package summarised at two A4 pages, ready to print\nVignettes are supporting documents that are available for many packages. They give examples and explain functions available in the package. You can discover vignettes by accessing the help page for a package, or via the browseVignettes() function, which will get you to the overall list. Or you can just try by typing specific names e.g.¬†vignette(‚Äúdplyr‚Äù)\n[R studio community] (https://forum.posit.co/) Questions sorted by packages, nice to check when looking for frequently asked questions.\nStack Overflow. You probably already came across Stack Overflow if you were trying to Google something, as it suggests answers to coding related questions. It is a good environment to ask questions or try to find if somebody already asked the same things before. Be specific about the coding style. E.g. How to separate variable using tidyverse?\nGitHub is a great source - you can find there data, projects, packages, instructions. If you stay till the end of this course we will show you more.\nAI tools are worth to ask. For example (i), you have a code and you do not understand it, so you can ask for explanation, or (ii) you want to get the code translated to another syntax (e.g.¬†from base R to tidyverse), (iii) or you want to know how to code something but you do not have a clue which packages to use‚Ä¶ We will train this a bit.\n\nOr just come and ask!",
    "crumbs": [
      "Data Manipulation and Visualization",
      "1 Introduction"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/1_introduction.html#exercises",
    "href": "DataManipulationVisualisation/1_introduction.html#exercises",
    "title": "1 Introduction",
    "section": "1.5 Exercises",
    "text": "1.5 Exercises\nFor exercises we will use either data that are published somewhere and give you the link, or we will ask you to download the data from the repository and save it into your project folder Link to Github folder\nThere will be some obligatory tasks, while voluntarily tasks will be marked by *.\nIn this chapter:\n1. Create project for this lesson, add subfolders (data, scripts..), download the data from the folder Forest_understory, and add them to your project. Import file called Axmanova-Forest-understory-diversity-analyses.xlsx into the working environment and check the structure. Prepare script with your notes, separated into sections.\n2. Create another project and start a new script, try switching between the projects. Delete this project.\n3. Find a cheatsheet for readxl. Is there anything more then data import from Excel?\n4. Use cheatsheet to find out how to import second sheet of Excel file. Try this on import of data/frozen_fauna/metadata. Which sheets are there and can you easily check the structure?\n5. Download Example0 from data/messy_data, save them into your data folder and import them to the working environment. Make the dataset tidy by renaming the variable names. Try one by one, or rename_all, or clean_names function from the janitor package. Save the tidy dataset as Example0_tidy.csv using function write_csv.\n6. Try importing the same, not cleaned file via Rstudio and describe pros/cons.\n7. *Check the folder messy data, what are the problems in examples1-5? We will learn how to fix them in next chapters directly in R, but can you at least imagine how you would do it in Excel?\n8. *Do you know what is reprex and how to prepare it?",
    "crumbs": [
      "Data Manipulation and Visualization",
      "1 Introduction"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/1_introduction.html#further-reading",
    "href": "DataManipulationVisualisation/1_introduction.html#further-reading",
    "title": "1 Introduction",
    "section": "1.6 Further reading",
    "text": "1.6 Further reading\nRStudio: Download and basic information https://posit.co/download/rstudio-desktop/\nDavid Zelen√Ω: Tutorial how to install R and Rstudio https://www.davidzeleny.net/anadat-r/doku.php/en:r\nDatacamp: Tutorial for R studio here\nWhy to organise your work in projects https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\nDavid Zelen√Ω clean and tidy script https://davidzeleny.net/wiki/doku.php/recol:clean_and_tidy_script\nTidyverse suggestions to good coding style https://style.tidyverse.org/\nR for data science book https://r4ds.hadley.nz/",
    "crumbs": [
      "Data Manipulation and Visualization",
      "1 Introduction"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/3_data_visualisation.html",
    "href": "DataManipulationVisualisation/3_data_visualisation.html",
    "title": "3 Data Visualisation",
    "section": "",
    "text": "In this chapter, we will cover the basics of data visualisation using the ggplot2 package in R. ggplot2 uses a conceptual framework called Grammar of Graphics , which allows you to compose graphs by combining independent components. Every graph produced with ggplot2 can be built from the same components: data, a coordinate system and geoms (visual marks representing data points). That is what makes ggplot2 so powerful. We will now explore how to create various types of plots, customize them, and save them for publications or presentations.\nSo let‚Äôs start. ggplot2 is a part of tidyverse, so you should have it installed already, and you can load it by running:\nlibrary(tidyverse)\nThis is a line that should appear at the beginning of each of your new scripts.\nTo make a plot, we first need some data. We will use a dataset of size measurements for three penguin species observed on three islands in the Palmer Achipelago (Antarctica).\nTo get the data, we need to load another package (if you get an error message, that there is no such package, install it first):\nlibrary(palmerpenguins)\nBy loading the package, we got access to a penguin dataset, that we might now call as an object called penguins. Before plotting, we can briefly look at the data structure:\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\nThe dataset contains information about 344 penguins, and there are 8 different variables. You can read more about them in the documentation by running ?penguins.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "3 Data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/3_data_visualisation.html#getting-started-scatterplot",
    "href": "DataManipulationVisualisation/3_data_visualisation.html#getting-started-scatterplot",
    "title": "3 Data Visualisation",
    "section": "3.1 Getting started: scatterplot",
    "text": "3.1 Getting started: scatterplot\nWe will now visualise the relationship between the different dimensions of the penguin bill:\n\n\n\n\n\nVisualisation with ggplot2 starts with the function ggplot(). This will define a plot object, where you can then add layers. The first argument to this function is data, which specifies which data to use for plotting. Running the following will create an empty plot, an empty canvas prepared for plotting desired layers onto.\n\nggplot(data = penguins)\n\n\n\n\n\n\n\n\nNext, we have to tell ggplot() how the data should be visualised. For this, we specify the mapping argument, which is always defined by the aes() function (aesthetics). The x and y arguments of the aes() function specify, which variables to map to the x and y axes of the plot.\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm))\n\n\n\n\n\n\n\n\nThe ggplot() now knows which variables will be displayed on each axes and added the axis names and value ranges to our empty plot. However, we still didn‚Äôt provide any information about how the data point should be displayed. To do so, we define a geom, geometrical object to represent the data. ggplot2 provides a wide variety of possible geometries, all defined by functions starting with geom_. Boxplots are drawn using boxplot geoms (geom_boxplot()), bar charts use bar geoms (geom_bar()), line charts use line geoms (geom_line()), scatterplots use point geoms (geom_point()), etc. We now aim to create a scatterplot, which means adding points to our plot using the geom_point() function:\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNow, the plot with a point for each row in the data appears. However, there is a warning message in the console, which tells us that 2 rows contained missing values or values outside of the scale range. We didn‚Äôt set any limit for x or y axis, so it most likely means there are some missing values in the data. We will not focus on this point now, but the ideal next step would be to check the data, where the missing values appeared and why. If possible, correct missing data in the original data, load new data and continue.\nNote that we use + for adding layers to ggplot() instead of %&gt;% or |&gt;. This is because + in ggplot() existed earlier than the pipe was discovered. It might be confusing and a cause errors, but don‚Äôt worry, R will tell you what‚Äôs wrong if it happens:\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm)) |&gt; \n  geom_point()\n\nError in `geom_point()`:\n! `mapping` must be created by `aes()`.\n‚Ñπ Did you use `%&gt;%` or `|&gt;` instead of `+`?\n\n\nWhen we look at the scatterplot, there doesn‚Äôt appear to be a clear relationship between the penguin bill length and bill depth. Let‚Äôs add one more layer to our plot to check the relationship. To add a line based on linear regression, we use geom_smooth function with method = 'lm':\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point() + \n  geom_smooth(method = 'lm')\n\n\n\n\n\n\n\n\nNow it seems there is a slightly negative relationship, which is a bit contrary to the expectations. Moreover, if we focus on the positions of the points in the scatterplot are a bit clustered. Let‚Äôs recall the structure of our data. We have measurements of three different species in the dataset. What if this is the cause? Let‚Äôs incorporate the species identity into our visualisation. We can do this by adding colour to the points. For this we need to modify the aesthetics:\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm, colour = species)) +\n  geom_point() + \n  geom_smooth(method = 'lm')\n\n\n\n\n\n\n\n\nNow it is clear that species identity is really important and the relationship between the bill dimensions is in fact positive. This is a classical example of the Simpson‚Äôs paradox (a relationship appears in several groups of data, but disappears or reverses when the groups are combined).\nIn addition to the colour, we can also distinguish species in the plot by adding shape aesthetics.\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm, colour = species, shape = species)) +\n  geom_point() + \n  geom_smooth(method = 'lm')\n\n\n\n\n\n\n\n\nNote that the legend is automatically updated to reflect both the different colours and shapes of the points.\nLet‚Äôs play a bit more with the different shapes and colours, the points could be better distinguished from each other if the points were black-delimited. This might be changed by the specification of scale for the shape aesthetics. Bounded shapes with coloured inside are 21-25 and we want to use the circle, square and triangle:\n\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm, colour = species, shape = species)) +\n  geom_point() + \n  geom_smooth(method = 'lm') + \n  scale_shape_manual(values = c(21, 22, 24))\n\n\n\n\n\n\n\n\nOh, but this is not what we wanted, the shapes have only coloured boundaries, but no fill. Let‚Äôs make it correctly. The fill colour is specified by the fill aesthetics, so we have to add this one. Moreover, the colour aesthetics is now specified directly in the ggplot() function, which means it applies to all layers in the plot. But we want all points to have black borders, so the colour should apply only to the lines. We can do this by moving the colour aesthetics to the geom_smooth() layer.\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm, fill = species, shape = species)) +\n  geom_point() + \n  geom_smooth(aes(colour = species), method = 'lm') + \n  scale_shape_manual(values = c(21, 22, 24))\n\n\n\n\n\n\n\n\nMuch nicer! Note that adding the fill aesthetics to the ggplot() also changed the colour of the confidence intervals for the regression lines.\nThe legend is now showing all aesthetics differentiating the groups in the plot. Maybe we don‚Äôt need to display all of them. It would be enough to display a legend for the points, because the lines have the same colours. We can switch off legend for a given layer using show.legend = F:\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm, fill = species, shape = species)) +\n  geom_point() + \n  geom_smooth(aes(colour = species), method = 'lm', show.legend = F) + \n  scale_shape_manual(values = c(21, 22, 24))\n\n\n\n\n\n\n\n\nTo make the plot more publication-ready, we should pay more attention to the axes labels. We can change them using the labs() function. To rename the legend, we have to specify labels for all aesthetics used to distinguish the different categories.\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm, fill = species, shape = species)) +\n  geom_point() + \n  geom_smooth(aes(colour = species), method = 'lm', show.legend = F) + \n  scale_shape_manual(values = c(21, 22, 24)) + \n  labs(x = 'Bill length (mm)', y = 'Bill depth (mm)', fill = 'Species', shape = 'Species', colour = 'Species')\n\n\n\n\n\n\n\n\nAlmost publication-ready, except the grey background is not very nice. It might be easily remove by adding a different theme. One of our favourites is theme_bw(), meaning black and white, but you can experiment with different ones or even define your own.\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm, fill = species, shape = species)) +\n  geom_point() + \n  geom_smooth(aes(colour = species), method = 'lm', show.legend = F) + \n  scale_shape_manual(values = c(21, 22, 24)) + \n  labs(x = 'Bill length (mm)', y = 'Bill depth (mm)', fill = 'Species', shape = 'Species', colour = 'Species') + \n  theme_bw()\n\n\n\n\n\n\n\n\nThis is our final plot showing the relationship between penguin bill dimensions of three different species.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "3 Data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/3_data_visualisation.html#histogram",
    "href": "DataManipulationVisualisation/3_data_visualisation.html#histogram",
    "title": "3 Data Visualisation",
    "section": "3.2 Histogram",
    "text": "3.2 Histogram\nLet‚Äôs explore the dataset more and take a look at different plot types. For example, we can look at the distribution of the penguin body mass using a histogram. We only specify x aesthetics here, because the histogram divides x-axis into equally spaced bins and then uses the height of the bar to display the number of observations that fall into each bin. The binwidth argument sets the width of the bins.\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 200)\n\n\n\n\n\n\n\n\nFor now, we will not go into detail on how to improve the appearance of this plot, you can take it as an exercise and experiment with it on your own.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "3 Data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/3_data_visualisation.html#boxplot",
    "href": "DataManipulationVisualisation/3_data_visualisation.html#boxplot",
    "title": "3 Data Visualisation",
    "section": "3.3 Boxplot",
    "text": "3.3 Boxplot\nThere is surely also a difference between different penguin species. We can visualise the differences using a boxplot:\n\nggplot(penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nWe can also colour the boxes using the fill aesthetics. To make this plot nicer, we will again change the theme of the plot. We can also change the label of the y axis, while the label of the x axis is a bit redundant and it would be better to remove it. This might be done within the theme() function. That‚Äôs where we can customise the properties of different plot components, such as axis labels, legend or background grid lines. To remove the given component, we set the argument to element_blank().\n\nggplot(penguins, aes(x = species, y = body_mass_g, fill = species)) +\n  geom_boxplot() + \n  labs(y = 'Body mass (g)', fill = 'Species') + \n  theme_bw() + \n  theme(axis.title.x = element_blank())",
    "crumbs": [
      "Data Manipulation and Visualization",
      "3 Data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/3_data_visualisation.html#bar-chart",
    "href": "DataManipulationVisualisation/3_data_visualisation.html#bar-chart",
    "title": "3 Data Visualisation",
    "section": "3.4 Bar chart",
    "text": "3.4 Bar chart\nTo examine the distribution of a categorical variable, we can use a bar chart. The penguin measurements come from three different islands, let‚Äôs see how the distribution of measurement across the islands looks like:\n\nggplot(penguins, aes(x = island)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nAnd were all three penguin species measured at each of the three islands? We can see that when we map species using the fill aesthetics. The colour would control the border colour of the bars. We can also set that all bars should have black borders by setting colour = 'black' in geom_bar. We can also directly modify the theme and plot labels.\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(colour = 'black') + \n  labs(x = 'Island', y = 'Number of individuals', fill = 'Species') + \n  theme_bw()\n\n\n\n\n\n\n\n\nInstead of the number of individuals, we can also display the relative frequency of different species at the islands by setting position = 'fill'.\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(colour = 'black', position = 'fill') + \n  labs(x = 'Island', y = 'Relative frequency', fill = 'Species') + \n  theme_bw()",
    "crumbs": [
      "Data Manipulation and Visualization",
      "3 Data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/3_data_visualisation.html#saving-your-plots",
    "href": "DataManipulationVisualisation/3_data_visualisation.html#saving-your-plots",
    "title": "3 Data Visualisation",
    "section": "3.5 Saving your plots",
    "text": "3.5 Saving your plots\nOnce you are satisfied with your plot, it is a good idea to save it as an image. The best way to save a plot from ggplot() is to use the ggsave() function. You have to specify the name of your file. Good practice is to save all plots to a dedicated folder, for example plots. By default, the last plot displayed in the viewer pane will be saved, and the dimensions will be the same as the current extent of the viewer pane. It is not the best idea to rely on this because the size of the plot will change every time you change the extent of your viewer pane. Therefore, it is a good practice to set the size of your figure using the width and height arguments. Sometimes it requires a bit of experimentation, but since you figure out the optimal settings, you can redraw the plot as many times as you want and always save it with the same dimensions.\n\nggsave('plots/island_relative_frequency.png', width = 6, height = 4)",
    "crumbs": [
      "Data Manipulation and Visualization",
      "3 Data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/3_data_visualisation.html#exercises",
    "href": "DataManipulationVisualisation/3_data_visualisation.html#exercises",
    "title": "3 Data Visualisation",
    "section": "3.6 Exercises",
    "text": "3.6 Exercises\n\nUse the dataset Axmanova-Forest-understory-diversity-analyses.xslx and visualise the relationship between species richness of forest herb layer and the tree canopy cover. Is the relationship the same in different forest types?\nDraw a boxplot showing the differences in forest herb layer species richness in different forest types. Which forest type appears to be the most species-rich? * Would there be another way to visualise the relationship between the herb-layer species richness and forest type? Explore the ggplot extensions gallery and find a different plot type that might be useful here.\nLoad data of squirrel observations from the Central Park Squirrel Census using this line: read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2023/2023-05-23/squirrel_data.csv') Squirrels of which colour were the most common? Draw a barplot to visualise the differences. * Try to find a way to colour the bars with colours resembling the squirrel colours.\nLoad the Pokemon dataset using this line: read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv'). Visualise the distribution of Pok√©mon weights. * Try to use at least two different geom functions.\n* How would you transform the variable before an analysis? Find a way to visualise the distribution on a transformed scale using a ggplot function.\nWhat is the relationship between the attack and special attack power of water-type Pok√©mons?\nWhich Pok√©mon type has the highest attack power? Visualise the relationship.\nExplore the relationship between the Pok√©mon attack and defense power. Distinguish different Pok√©mon types. * When using different colors for many categories, the plot gets quite messy, try to come up with a solution to distinguish the Pok√©mon types more clearly in the plot.\nModify axis labels, legend, colours, etc. of all plots you created so far, so that you like their appearance and save them to the folder plots.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "3 Data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/3_data_visualisation.html#further-reading",
    "href": "DataManipulationVisualisation/3_data_visualisation.html#further-reading",
    "title": "3 Data Visualisation",
    "section": "3.7 Further reading",
    "text": "3.7 Further reading\nggplot2 vignette: https://ggplot2.tidyverse.org\nR 4 Data Science: https://r4ds.hadley.nz/data-visualize.html\nCheatsheet: https://rstudio.github.io/cheatsheets/html/data-visualization.html\nggplot2: Elegant Graphics for Data Analysis (3e): https://ggplot2-book.org\nR Graphics Cookbook: https://r-graphics.org\nggplot Extensions: https://exts.ggplot2.tidyverse.org",
    "crumbs": [
      "Data Manipulation and Visualization",
      "3 Data visualisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/7_8_automatisation.html",
    "href": "DataManipulationVisualisation/7_8_automatisation.html",
    "title": "7 + 8 Automatisation",
    "section": "",
    "text": "‚ÄúCopy-and-paste is a powerful tool, but you should avoid doing it more than twice.‚Äù ‚Äì Hadley Wickham, R for Data Science\nIt‚Äôs not only a matter of the script length. Repeating the same code multiple times might easily lead to errors and inconsistencies, and it is therefore better to avoid it. There are multiple ways to reduce copy-pasting when we want to repeat a similar operation multiple times. In this chapter, you will learn how to write your own function and some tools for iteration, including for loops and functions from the purrr package.\nThroughout this chapter, we will use the following packages:\nlibrary(palmerpenguins)\nlibrary(broom)\nlibrary(tidyverse)",
    "crumbs": [
      "Data Manipulation and Visualization",
      "7 + 8 Automatisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/7_8_automatisation.html#functions",
    "href": "DataManipulationVisualisation/7_8_automatisation.html#functions",
    "title": "7 + 8 Automatisation",
    "section": "7.1 Functions",
    "text": "7.1 Functions\nIn more complex data analysis tasks, when you need to repeat a similar operation multiple times, e.g.¬†calculate the same model for multiple subsets of data, calculate models with the same explanatory variables for different response variables, or draw similarly looking plots for multiple variables, it becomes really useful to be able to write your own function and hide the repeated code into it. A huge advantage of only writing the code once and saving it as a function is that when you have to change something, you only do it once and thus prevent mistakes like replacing the variable name in one place but not in the other, etc. In the long term, it also saves time and improves the understandability of the code, as the script does not end up being hundreds or thousands of lines long and all important commands are in one place.\nWe will use a penguin dataset that you know already:\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\n\n7.1.1 Vector functions\nLet‚Äôs say we want to standardise each measured variable in the dataset, and just imagine for now that there is no scale() function, so we have to do it manually. We would end up with something like this:\n\npenguins |&gt; \n  mutate(bill_length_mm = (bill_length_mm - mean(bill_length_mm, na.rm = T))/sd(bill_length_mm, na.rm = T), \n         bill_depth_mm = (bill_depth_mm - mean(bill_depth_mm, na.rm = T))/sd(bill_depth_mm, na.rm = T),\n         flipper_length_mm = (flipper_length_mm - mean(flipper_length_mm, na.rm = T))/sd(flipper_length_mm, na.rm = T),\n         body_mass_g = (body_mass_g - mean(body_mass_g, na.rm = T))/sd(body_mass_g, na.rm = T))\n\n# A tibble: 344 √ó 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Adelie  Torgersen         -0.883         0.784            -1.42      -0.563 \n 2 Adelie  Torgersen         -0.810         0.126            -1.06      -0.501 \n 3 Adelie  Torgersen         -0.663         0.430            -0.421     -1.19  \n 4 Adelie  Torgersen         NA            NA                NA         NA     \n 5 Adelie  Torgersen         -1.32          1.09             -0.563     -0.937 \n 6 Adelie  Torgersen         -0.847         1.75             -0.776     -0.688 \n 7 Adelie  Torgersen         -0.920         0.329            -1.42      -0.719 \n 8 Adelie  Torgersen         -0.865         1.24             -0.421      0.590 \n 9 Adelie  Torgersen         -1.80          0.480            -0.563     -0.906 \n10 Adelie  Torgersen         -0.352         1.54             -0.776      0.0602\n# ‚Ñπ 334 more rows\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nWhen creating such a code, it is quite easy to forget to replace the variable name in one place when copying it. To avoid that and make the code easier to read, we can transform the code into a function. We need three things to do that:\n\na function name, this should be concise and informative (please avoid myfunction1(), etc.) and not mess up already existing functions, we will use custom_scale to distinguish our function from the scale().\narguments, which are the things that we want to vary across calls, in our case, we have just one numerical variable we are working with, so we will call it x.\nbody, that is the code that stays the same across calls.\n\nEvery function defined in R has the following structure:\n\nname &lt;- function(arguments){\n  body\n}\n\nIn our case, the function would look like this:\n\ncustom_scale &lt;- function(x){\n  (x - mean(x, na.rm = T))/sd(x, na.rm = T)\n}\n\nWhen we run this code, our new function is saved into the environment, and we can use it as any other function. We created a function that takes a vector and returns a vector of the same length that might be use within the mutate() function.\n\npenguins |&gt; \n  mutate(bill_length_mm = custom_scale(bill_length_mm), \n         bill_depth_mm = custom_scale(bill_depth_mm),\n         flipper_length_mm = custom_scale(flipper_length_mm),\n         body_mass_g = custom_scale(body_mass_g))\n\n# A tibble: 344 √ó 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Adelie  Torgersen         -0.883         0.784            -1.42      -0.563 \n 2 Adelie  Torgersen         -0.810         0.126            -1.06      -0.501 \n 3 Adelie  Torgersen         -0.663         0.430            -0.421     -1.19  \n 4 Adelie  Torgersen         NA            NA                NA         NA     \n 5 Adelie  Torgersen         -1.32          1.09             -0.563     -0.937 \n 6 Adelie  Torgersen         -0.847         1.75             -0.776     -0.688 \n 7 Adelie  Torgersen         -0.920         0.329            -1.42      -0.719 \n 8 Adelie  Torgersen         -0.865         1.24             -0.421      0.590 \n 9 Adelie  Torgersen         -1.80          0.480            -0.563     -0.906 \n10 Adelie  Torgersen         -0.352         1.54             -0.776      0.0602\n# ‚Ñπ 334 more rows\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nWe can, of course, reduce the duplication even further by using the across() function:\n\npenguins |&gt; \n  mutate(across(c(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g), ~custom_scale(.x)))\n\n# A tibble: 344 √ó 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Adelie  Torgersen         -0.883         0.784            -1.42      -0.563 \n 2 Adelie  Torgersen         -0.810         0.126            -1.06      -0.501 \n 3 Adelie  Torgersen         -0.663         0.430            -0.421     -1.19  \n 4 Adelie  Torgersen         NA            NA                NA         NA     \n 5 Adelie  Torgersen         -1.32          1.09             -0.563     -0.937 \n 6 Adelie  Torgersen         -0.847         1.75             -0.776     -0.688 \n 7 Adelie  Torgersen         -0.920         0.329            -1.42      -0.719 \n 8 Adelie  Torgersen         -0.865         1.24             -0.421      0.590 \n 9 Adelie  Torgersen         -1.80          0.480            -0.563     -0.906 \n10 Adelie  Torgersen         -0.352         1.54             -0.776      0.0602\n# ‚Ñπ 334 more rows\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThere are some useful RStudio keyboard shortcuts you can use to work with functions:\n\nTo find a definition of any function, place a cursor on the name of the function in the script and press F2.\nTo extract a function from a code you have written, use Alt + Ctrl + X. Just be sure you always check the results, because sometimes it will not do exactly what you expect, so you will have to make some adjustments.\n\nWe can also write summary functions to be used in a summarise() call. For example, we could calculate the difference between the minimum and maximum values of the given variable:\n\nrange_diff &lt;- function(x){\n  max(x, na.rm = T) - min(x, na.rm = T)\n}\n\npenguins |&gt; \n  summarize(bill_length_mm = range_diff(bill_length_mm), \n            bill_depth_mm = range_diff(bill_depth_mm))\n\n# A tibble: 1 √ó 2\n  bill_length_mm bill_depth_mm\n           &lt;dbl&gt;         &lt;dbl&gt;\n1           27.5           8.4\n\n\n\n\n7.1.2 Data frame functions\nTill now, we have written several vector functions that might be used within dplyr functions. But functions may operate even at the data frame level. We will show here a real-world example of data sampled in three types of sand vegetation - pioneer sand vegetation (Corynephorion), acidophilous sand grasslands (Armerion) and basiphilous sand grasslands (Festucion valesiacae). The species data of all three vegetation types are saved in a long format in one file, and the header data with cluster assignment in a second file.\n\nspe_long &lt;- read_csv('data/sands/sands_spe_long.csv')\n\nRows: 3154 Columns: 3\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): valid_name\ndbl (2): releve_nr, cover_perc\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(spe_long)\n\nRows: 3,154\nColumns: 3\n$ releve_nr  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,‚Ä¶\n$ valid_name &lt;chr&gt; \"Achillea millefolium agg.\", \"Artemisia campestris\", \"Carex‚Ä¶\n$ cover_perc &lt;dbl&gt; 0.5, 0.5, 0.5, 3.0, 0.5, 15.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5‚Ä¶\n\nhead &lt;- read_csv('data/sands/sands_head.csv') |&gt; \n  select(releve_nr, cluster)\n\nRows: 172 Columns: 89\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (40): country, reference, nr_in_tab, coverscale, author, syntaxon, moss_...\ndbl (46): releve_nr, table_nr, date, surf_area, altitude, exposition, inclin...\nlgl  (3): rs_project, maniptyp, name_ass\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(head)\n\nRows: 172\nColumns: 2\n$ releve_nr &lt;dbl&gt; 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, ‚Ä¶\n$ cluster   &lt;chr&gt; \"Corynephorion\", \"Armerion\", \"Corynephorion\", \"Corynephorion‚Ä¶\n\n\nImagine we now want to run an ordination analysis that needs species data in a wide format for each of the three vegetation types separately. We need to subset the species data to only the selected vegetation type, select only relevant columns, square-root the species abundances, and transform the data into a wide format. We can incorporate all these steps into a single function, that we will then run three times for different subsets:\n\nsubset_to_wide &lt;- function(data_long, veg_type){\n  data_long |&gt; \n    semi_join(head |&gt; filter(cluster == veg_type)) |&gt;\n    select(releve_nr, valid_name, cover_perc) |&gt; \n    mutate(cover_perc = sqrt(cover_perc)) |&gt; \n    pivot_wider(names_from = valid_name, values_from = cover_perc, values_fill = 0) |&gt; \n    select(-releve_nr)\n}\n\nspe_wide_cory &lt;- subset_to_wide(spe_long, 'Corynephorion')\n\nJoining with `by = join_by(releve_nr)`\n\nspe_wide_arm &lt;- subset_to_wide(spe_long, 'Armerion')\n\nJoining with `by = join_by(releve_nr)`\n\nspe_wide_fes &lt;- subset_to_wide(spe_long, 'Festucion valesiacae')\n\nJoining with `by = join_by(releve_nr)`\n\n\nWriting your own functions with the dplyr and tidyr calls inside sometimes also brings some challenges. We unfortunately do not have enough space here to deal with them, but there are great sources with detailed explanation, where you can learn more or find help if needed, e.g.¬†https://r4ds.hadley.nz/functions.html#data-frame-functions, programming with dplyr, programming with tidyr, What is data-masking and why do I need {{?.\n\n\n7.1.3 Plot functions\nSometimes it is also useful to reduce the amount of replicated code when plotting many different things in a similar way. The plot functions work similarly to the data frame functions, just return a plot instead of a data frame. For example, we might want to visualise the relationship between bill length and bill depth of three different penguin species separately. We have to first filter our penguin dataset to contain data on only one species, and then create a scatterplot using a ggplot sequence. This is how we would write the code for plotting the data for one species:\n\npenguins |&gt; \n    filter(species == 'Adelie') |&gt; \n    ggplot(aes(bill_length_mm, bill_depth_mm)) +\n    geom_point() +\n    theme_bw() +\n    labs(title = 'Adelie', x = 'Bill length [mm]', y = 'Bill depth [mm]')\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nLet‚Äôs now turn this code into a function instead of copy-pasting it two more times to plot the same relationship for the two other species:\n\nplot_species &lt;- function(data, species_name){\n  data |&gt; \n    filter(species == species_name) |&gt; \n    ggplot(aes(bill_length_mm, bill_depth_mm)) +\n    geom_point() +\n    theme_bw() +\n    labs(title = species_name, x = 'Bill length [mm]', y = 'Bill depth [mm]')\n}\nplot_species(penguins, 'Adelie')\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nTo learn more about reducing duplication in your ggplot2 code look here: https://r4ds.hadley.nz/functions.html#plot-functions, Programming with ggplot2, https://ggplot2.tidyverse.org/articles/ggplot2-in-packages.html.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "7 + 8 Automatisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/7_8_automatisation.html#for-loops",
    "href": "DataManipulationVisualisation/7_8_automatisation.html#for-loops",
    "title": "7 + 8 Automatisation",
    "section": "7.2 For loops",
    "text": "7.2 For loops\nWe will now move to the iteration part of this chapter, which means repeating the same action multiple times on different objects. In any programming language, it is possible to automate such repetitions using a for loop. The basic structure of a for loop looks like this:\n\nfor (variable in sequence) {\n  # do something with the variable\n}\n\nThe for loop takes one variable from a given sequence, runs the code inside {} for this variable and then moves to the next variable in the sequence. A basic example might be printing numbers from a sequence:\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nThe for loop takes one number, prints it, then takes the next one, prints it, and so on till the end of the sequence.\nWe can, for example, take our plot function to plot the scatterplot of bill length and bill depth of individual species and loop over the species names to sequentially make a plot for all species.\n\nfor (species_name in unique(penguins$species)) {\n  plot_species(penguins, species_name) |&gt; \n    print()\n}\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are always multiple ways to get to the same result, and this is also true for iteration in R. The purrr package has powerful tools to iterate over multiple elements. But even when you choose to prefer purrr solutions, it is worth being familiar with for loops and their functionality, because you might see them often in the code of other people, and they are universal across programming languages.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "7 + 8 Automatisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/7_8_automatisation.html#purrr-and-working-with-nested-dataframes",
    "href": "DataManipulationVisualisation/7_8_automatisation.html#purrr-and-working-with-nested-dataframes",
    "title": "7 + 8 Automatisation",
    "section": "7.3 purrr and working with nested dataframes",
    "text": "7.3 purrr and working with nested dataframes\nWe already went through most of the tidyverse packages, but we didn‚Äôt talk about the purrr package yet. purrr provides powerful tools for automatisation of tasks that need to be repeated multiple times, e.g.¬†for each file in a directory, each element of a list, each dataframe‚Ä¶ They allow you to replace for loops with map() functions, which might be more powerful, readable and consistent with the rest of tidyverse.\nLet‚Äôs start with the task of reading multiple files at once. Imagine you have multiple files that are of the same structure, but for some reason, they are stored in multiple files. As example data, we will use the gapminder dataset, which provides values for life expectancy, GDP per capita, and population size. The data we have in the gapminder folder is divided by year, and we now want to load them all and combine them into a single tibble. We could do that by copy-pasting the read_csv() function twelve times, but there is a more elegant way. Let‚Äôs list the files first:\n\npaths &lt;- list.files('data/gapminder/', pattern = '.csv', full.names = T)\npaths\n\n [1] \"data/gapminder/gapminder_1952.csv\" \"data/gapminder/gapminder_1957.csv\"\n [3] \"data/gapminder/gapminder_1962.csv\" \"data/gapminder/gapminder_1967.csv\"\n [5] \"data/gapminder/gapminder_1972.csv\" \"data/gapminder/gapminder_1977.csv\"\n [7] \"data/gapminder/gapminder_1982.csv\" \"data/gapminder/gapminder_1987.csv\"\n [9] \"data/gapminder/gapminder_1992.csv\" \"data/gapminder/gapminder_1997.csv\"\n[11] \"data/gapminder/gapminder_2002.csv\" \"data/gapminder/gapminder_2007.csv\"\n\n\nThe map() function works similarly to across(), but instead of doing something to each column in a data frame, it does something to each element of a vector. It is an analogy of a for loop, the function takes each element of a sequence and applies a function to it. We can use it now to read all 12 csv files in one line:\n\nfiles &lt;- map(paths, ~read_csv(.x))\n\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 142 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, continent\ndbl (3): lifeExp, pop, gdpPercap\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(files)\n\nList of 12\n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 28.8 55.2 43.1 30 62.5 ...\n  ..$ pop      : num [1:142] 8425333 1282697 9279525 4232095 17876956 ...\n  ..$ gdpPercap: num [1:142] 779 1601 2449 3521 5911 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 30.3 59.3 45.7 32 64.4 ...\n  ..$ pop      : num [1:142] 9240934 1476505 10270856 4561361 19610538 ...\n  ..$ gdpPercap: num [1:142] 821 1942 3014 3828 6857 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 32 64.8 48.3 34 65.1 ...\n  ..$ pop      : num [1:142] 10267083 1728137 11000948 4826015 21283783 ...\n  ..$ gdpPercap: num [1:142] 853 2313 2551 4269 7133 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 34 66.2 51.4 36 65.6 ...\n  ..$ pop      : num [1:142] 11537966 1984060 12760499 5247469 22934225 ...\n  ..$ gdpPercap: num [1:142] 836 2760 3247 5523 8053 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 36.1 67.7 54.5 37.9 67.1 ...\n  ..$ pop      : num [1:142] 13079460 2263554 14760787 5894858 24779799 ...\n  ..$ gdpPercap: num [1:142] 740 3313 4183 5473 9443 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 38.4 68.9 58 39.5 68.5 ...\n  ..$ pop      : num [1:142] 14880372 2509048 17152804 6162675 26983828 ...\n  ..$ gdpPercap: num [1:142] 786 3533 4910 3009 10079 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 39.9 70.4 61.4 39.9 69.9 ...\n  ..$ pop      : num [1:142] 12881816 2780097 20033753 7016384 29341374 ...\n  ..$ gdpPercap: num [1:142] 978 3631 5745 2757 8998 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 40.8 72 65.8 39.9 70.8 ...\n  ..$ pop      : num [1:142] 13867957 3075321 23254956 7874230 31620918 ...\n  ..$ gdpPercap: num [1:142] 852 3739 5681 2430 9140 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 41.7 71.6 67.7 40.6 71.9 ...\n  ..$ pop      : num [1:142] 16317921 3326498 26298373 8735988 33958947 ...\n  ..$ gdpPercap: num [1:142] 649 2497 5023 2628 9308 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 41.8 73 69.2 41 73.3 ...\n  ..$ pop      : num [1:142] 22227415 3428038 29072015 9875024 36203463 ...\n  ..$ gdpPercap: num [1:142] 635 3193 4797 2277 10967 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 42.1 75.7 71 41 74.3 ...\n  ..$ pop      : num [1:142] 25268405 3508512 31287142 10866106 38331121 ...\n  ..$ gdpPercap: num [1:142] 727 4604 5288 2773 8798 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n $ : spc_tbl_ [142 √ó 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n  ..$ country  : chr [1:142] \"Afghanistan\" \"Albania\" \"Algeria\" \"Angola\" ...\n  ..$ continent: chr [1:142] \"Asia\" \"Europe\" \"Africa\" \"Africa\" ...\n  ..$ lifeExp  : num [1:142] 43.8 76.4 72.3 42.7 75.3 ...\n  ..$ pop      : num [1:142] 31889923 3600523 33333216 12420476 40301927 ...\n  ..$ gdpPercap: num [1:142] 975 5937 6223 4797 12779 ...\n  ..- attr(*, \"spec\")=\n  .. .. cols(\n  .. ..   country = col_character(),\n  .. ..   continent = col_character(),\n  .. ..   lifeExp = col_double(),\n  .. ..   pop = col_double(),\n  .. ..   gdpPercap = col_double()\n  .. .. )\n  ..- attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nWe got a list with 12 data frames. To access the first element of the list, we would call files[[1]]. For further work with lists and map() functions, it is worth remembering that the elements of a list are called with the double square brackets.\nTo combine all data frames in a list, we can use list_rbind():\n\ngapminder_df &lt;- map(paths, ~read_csv(.x)) |&gt; \n  list_rbind()\nglimpse(gapminder_df)\n\nRows: 1,704\nColumns: 5\n$ country   &lt;chr&gt; \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", ‚Ä¶\n$ continent &lt;chr&gt; \"Asia\", \"Europe\", \"Africa\", \"Africa\", \"Americas\", \"Oceania\",‚Ä¶\n$ lifeExp   &lt;dbl&gt; 28.801, 55.230, 43.077, 30.015, 62.485, 69.120, 66.800, 50.9‚Ä¶\n$ pop       &lt;dbl&gt; 8425333, 1282697, 9279525, 4232095, 17876956, 8691212, 69277‚Ä¶\n$ gdpPercap &lt;dbl&gt; 779.4453, 1601.0561, 2449.0082, 3520.6103, 5911.3151, 10039.‚Ä¶\n\n\nBut we somehow lost the information about the year. To fix it, we store the file names in the data frame. First step is to set names of the list elements of paths, the basename() function extracts just the file name from the path. Second, we save the names in a resulting data frame to a column called year.\n\ngapminder_df &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(~read_csv(.x)) |&gt; \n  list_rbind(names_to = 'year')\nglimpse(gapminder_df)\n\nRows: 1,704\nColumns: 6\n$ year      &lt;chr&gt; \"gapminder_1952.csv\", \"gapminder_1952.csv\", \"gapminder_1952.‚Ä¶\n$ country   &lt;chr&gt; \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", ‚Ä¶\n$ continent &lt;chr&gt; \"Asia\", \"Europe\", \"Africa\", \"Africa\", \"Americas\", \"Oceania\",‚Ä¶\n$ lifeExp   &lt;dbl&gt; 28.801, 55.230, 43.077, 30.015, 62.485, 69.120, 66.800, 50.9‚Ä¶\n$ pop       &lt;dbl&gt; 8425333, 1282697, 9279525, 4232095, 17876956, 8691212, 69277‚Ä¶\n$ gdpPercap &lt;dbl&gt; 779.4453, 1601.0561, 2449.0082, 3520.6103, 5911.3151, 10039.‚Ä¶\n\n\nStill not perfect, it would be nice to extract just the year from the file name. The easiest way to do it in this case is to use the parse_number() function that extracts just a number from a string:\n\ngapminder_df &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(~read_csv(.x)) |&gt; \n  list_rbind(names_to = 'year') |&gt; \n  mutate(year = parse_number(year))\nglimpse(gapminder_df)\n\nRows: 1,704\nColumns: 6\n$ year      &lt;dbl&gt; 1952, 1952, 1952, 1952, 1952, 1952, 1952, 1952, 1952, 1952, ‚Ä¶\n$ country   &lt;chr&gt; \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", ‚Ä¶\n$ continent &lt;chr&gt; \"Asia\", \"Europe\", \"Africa\", \"Africa\", \"Americas\", \"Oceania\",‚Ä¶\n$ lifeExp   &lt;dbl&gt; 28.801, 55.230, 43.077, 30.015, 62.485, 69.120, 66.800, 50.9‚Ä¶\n$ pop       &lt;dbl&gt; 8425333, 1282697, 9279525, 4232095, 17876956, 8691212, 69277‚Ä¶\n$ gdpPercap &lt;dbl&gt; 779.4453, 1601.0561, 2449.0082, 3520.6103, 5911.3151, 10039.‚Ä¶\n\n\nIt might be a good idea to save the resulting data frame as a single csv file now to make future data loading easier.\n\nwrite_csv(gapminder_df, 'data/gapminder_clean/gapminder.csv')\n\npurrr contains not only the map() function, but also it relatives, so we will look at the differences between them now:\n\nmap() makes a list\nmap_lgl() makes a logical vector\nmap_int() makes an integer vector\nmap_dbl() makes a double vector\nmap_chr() makes a character vector\n\nEach of the above-mentioned functions takes a vector input, applies a function to each element and returns a vector of the same length.\n\nmap2() takes two vectors, usually of the same length and iterates over two arguments at a time\n\nAnd there is also a group of walk() functions, which return their side-effects and return the input .x. They might be used, for example, for saving multiple files or plots.\nLet‚Äôs say, we want to save our gapminder data divided by continent. We first make a nested data frame by continent. This is something similar to group_by(), we take a variable that makes groups in our dataset and divide the rest of the data according to this variable. The grouping variable stays in one column, and a smaller data frame is created for each level of this variable. All these smaller data frames are stored in the data column. We now want to save each of these smaller data frames as a separate csv file. We now create a column, where we define a path for each file to be saved.\n\ngapminder_nest &lt;- gapminder_df |&gt; \n  nest(data = -continent) |&gt; \n  mutate(path = paste0('data/gapminder_continent/gapminder_', continent, '.csv')) \n\nglimpse(gapminder_nest)\n\nRows: 5\nColumns: 3\n$ continent &lt;chr&gt; \"Asia\", \"Europe\", \"Africa\", \"Americas\", \"Oceania\"\n$ data      &lt;list&gt; [&lt;tbl_df[396 x 5]&gt;], [&lt;tbl_df[360 x 5]&gt;], [&lt;tbl_df[624 x 5]&gt;‚Ä¶\n$ path      &lt;chr&gt; \"data/gapminder_continent/gapminder_Asia.csv\", \"data/gapmin‚Ä¶\n\n\nWe can see that the data column is a list containing tibbles with different numbers of rows, but the same number of columns. To look at one of them we need to use the [[]] again.\n\ngapminder_nest$data[[1]]\n\n# A tibble: 396 √ó 5\n    year country          lifeExp       pop gdpPercap\n   &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1  1952 Afghanistan         28.8   8425333      779.\n 2  1952 Bahrain             50.9    120447     9867.\n 3  1952 Bangladesh          37.5  46886859      684.\n 4  1952 Cambodia            39.4   4693836      368.\n 5  1952 China               44   556263527      400.\n 6  1952 Hong Kong, China    61.0   2125900     3054.\n 7  1952 India               37.4 372000000      547.\n 8  1952 Indonesia           37.5  82052000      750.\n 9  1952 Iran                44.9  17272000     3035.\n10  1952 Iraq                45.3   5441766     4130.\n# ‚Ñπ 386 more rows\n\n\nAnd we can save all the tibbles in separate csv files at once using the walk2() call, which at each step takes one tibble from the data column and one path definition from the path column and runs the write_csv() function with these two arguments.\n\nwalk2(gapminder_nest$data, gapminder_nest$path, ~write_csv(.x, .y))\n\nThe work with nested data frames becomes really helpful when we want to perform the same calculation many times. We will work with the gapminder data again and try to answer the following questions: How does life expectancy change over time in individual countries? In which countries has the life expectancy risen the most over time?\nTo explore the data a little bit first, we can plot them:\n\ngapminder_df |&gt; \n  ggplot(aes(year, lifeExp, group = country)) +\n  geom_line()\n\n\n\n\n\n\n\n\nOverall, life expectancy has been steadily increasing over time, but we need some estimation of the trend in individual countries. A possible way to do this would be to fit a linear model to the data from each country and look at the estimate. Given the 142 countries in the dataset, we really do not want to run the code for each one manually with copy-pasted code. Because we want to work at the country level, we will now nest our data by country. To calculate a linear model for data from each country, we will iterate over the data column and save the resulting model to a new column. This might be done with map() within the mutate() call.\n\nby_country &lt;- gapminder_df |&gt; \n  nest(data = -country) |&gt; \n  mutate(m = map(data, ~lm(lifeExp~year, data = .x)))\n\nThe column m we just created is again a list and contains the results of linear models for the relationship between life expectancy and time for all countries. With each one of them, we can do whatever is possible with a model result:\n\nsummary(by_country$m[[1]])\n\n\nCall:\nlm(formula = lifeExp ~ year, data = .x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.5447 -0.9905 -0.2757  0.8847  1.6868 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -507.53427   40.48416  -12.54 1.93e-07 ***\nyear           0.27533    0.02045   13.46 9.84e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.223 on 10 degrees of freedom\nMultiple R-squared:  0.9477,    Adjusted R-squared:  0.9425 \nF-statistic: 181.2 on 1 and 10 DF,  p-value: 9.835e-08\n\n\nTo easily extract the estimates from the model, we will use tidy() function from the broom package. broom is not a part of the tidyverse, but it is a related package, which becomes very helpful when working with models within the tidyverse workflow, because it provides tools to convert statistical objects into tidy tibbles. The tidy() function summarizes information about the model components:\n\ntidy(by_country$m[[1]])\n\n# A tibble: 2 √ó 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept) -508.      40.5        -12.5 0.000000193 \n2 year           0.275    0.0205      13.5 0.0000000984\n\n\nAnd we can again use it to iterate over all models to get these summaries for all countries.\n\nby_country &lt;- gapminder_df |&gt; \n  nest(data = -country) |&gt; \n  mutate(m = map(data, ~lm(lifeExp~year, data = .x)), \n         m_tidy = map(m, ~tidy(.x)))\n\nglimpse(by_country)\n\nRows: 142\nColumns: 4\n$ country &lt;chr&gt; \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A‚Ä¶\n$ data    &lt;list&gt; [&lt;tbl_df[12 x 5]&gt;], [&lt;tbl_df[12 x 5]&gt;], [&lt;tbl_df[12 x 5]&gt;], [‚Ä¶\n$ m       &lt;list&gt; [-507.5342716, 0.2753287, -1.10629487, -0.95193823, -0.663581‚Ä¶\n$ m_tidy  &lt;list&gt; [&lt;tbl_df[2 x 5]&gt;], [&lt;tbl_df[2 x 5]&gt;], [&lt;tbl_df[2 x 5]&gt;], [&lt;tb‚Ä¶\n\n\nThe summary is now in a tibble, but there is still a list of tibbles in the m_tidy column. To get the results to a data frame where we can sort the values and filter across all values, we need to unnest().\n\nby_country &lt;- gapminder_df |&gt; \n  nest(data = -country) |&gt; \n  mutate(m = map(data, ~lm(lifeExp~year, data = .x)), \n         m_tidy = map(m, ~tidy(.x))) |&gt; \n  unnest(m_tidy)\n\nglimpse(by_country)\n\nRows: 284\nColumns: 8\n$ country   &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Albania\", \"Albania\", \"Algeria‚Ä¶\n$ data      &lt;list&gt; [&lt;tbl_df[12 x 5]&gt;], [&lt;tbl_df[12 x 5]&gt;], [&lt;tbl_df[12 x 5]&gt;],‚Ä¶\n$ m         &lt;list&gt; [-507.5342716, 0.2753287, -1.10629487, -0.95193823, -0.6635‚Ä¶\n$ term      &lt;chr&gt; \"(Intercept)\", \"year\", \"(Intercept)\", \"year\", \"(Intercept)\",‚Ä¶\n$ estimate  &lt;dbl&gt; -507.5342716, 0.2753287, -594.0725110, 0.3346832, -1067.8590‚Ä¶\n$ std.error &lt;dbl&gt; 40.484161954, 0.020450934, 65.655359062, 0.033166387, 43.802‚Ä¶\n$ statistic &lt;dbl&gt; -12.536613, 13.462890, -9.048348, 10.091036, -24.379118, 25.‚Ä¶\n$ p.value   &lt;dbl&gt; 1.934055e-07, 9.835213e-08, 3.943337e-06, 1.462763e-06, 3.07‚Ä¶\n\n\nWe now have a column for each column originally included in the tibbles inside m_tidy. The list-columns we did not unnest still remain list-columns. There are now two rows for each country, one for each model coefficient - the intercept and the year. We are not interested in model intercepts now, so we can filter them out. To see in which countries has the life expectancy risen the most over time, we can arrange the dataset according to the model estimate.\n\nby_country &lt;- gapminder_df |&gt; \n  nest(data = -country) |&gt; \n  mutate(m = map(data, ~lm(lifeExp~year, data = .x)), \n         m_tidy = map(m, ~tidy(.x))) |&gt; \n  unnest(m_tidy) |&gt; \n  filter(term == 'year') |&gt; \n  arrange(desc(estimate))\n\nglimpse(by_country)\n\nRows: 142\nColumns: 8\n$ country   &lt;chr&gt; \"Oman\", \"Vietnam\", \"Saudi Arabia\", \"Indonesia\", \"Libya\", \"Ye‚Ä¶\n$ data      &lt;list&gt; [&lt;tbl_df[12 x 5]&gt;], [&lt;tbl_df[12 x 5]&gt;], [&lt;tbl_df[12 x 5]&gt;],‚Ä¶\n$ m         &lt;list&gt; [-1470.085705, 0.772179, 0.3702564, -0.9886387, -1.7645338,‚Ä¶\n$ term      &lt;chr&gt; \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yea‚Ä¶\n$ estimate  &lt;dbl&gt; 0.7721790, 0.6716154, 0.6496231, 0.6346413, 0.6255357, 0.605‚Ä¶\n$ std.error &lt;dbl&gt; 0.039265234, 0.021970572, 0.034812325, 0.010796685, 0.025754‚Ä¶\n$ statistic &lt;dbl&gt; 19.665718, 30.568863, 18.660721, 58.781125, 24.288551, 22.82‚Ä¶\n$ p.value   &lt;dbl&gt; 2.530346e-09, 3.289412e-11, 4.221338e-09, 4.931386e-14, 3.18‚Ä¶\n\n\nOr we can just print out the top 10 countries:\n\nby_country |&gt; slice_max(estimate, n = 10)\n\n# A tibble: 10 √ó 8\n   country            data     m     term  estimate std.error statistic  p.value\n   &lt;chr&gt;              &lt;list&gt;   &lt;lis&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Oman               &lt;tibble&gt; &lt;lm&gt;  year     0.772    0.0393      19.7 2.53e- 9\n 2 Vietnam            &lt;tibble&gt; &lt;lm&gt;  year     0.672    0.0220      30.6 3.29e-11\n 3 Saudi Arabia       &lt;tibble&gt; &lt;lm&gt;  year     0.650    0.0348      18.7 4.22e- 9\n 4 Indonesia          &lt;tibble&gt; &lt;lm&gt;  year     0.635    0.0108      58.8 4.93e-14\n 5 Libya              &lt;tibble&gt; &lt;lm&gt;  year     0.626    0.0258      24.3 3.19e-10\n 6 Yemen, Rep.        &lt;tibble&gt; &lt;lm&gt;  year     0.605    0.0265      22.8 5.87e-10\n 7 West Bank and Gaza &lt;tibble&gt; &lt;lm&gt;  year     0.601    0.0332      18.1 5.59e- 9\n 8 Tunisia            &lt;tibble&gt; &lt;lm&gt;  year     0.588    0.0261      22.5 6.64e-10\n 9 Gambia             &lt;tibble&gt; &lt;lm&gt;  year     0.582    0.0192      30.3 3.57e-11\n10 Jordan             &lt;tibble&gt; &lt;lm&gt;  year     0.572    0.0319      17.9 6.31e- 9\n\n\nThe use of nested data frames and broom has great potential. Depending on the question, it is possible to filter only significant results, select models with the highest explanatory power, etc. To learn more about the automatisation using purrr and running many models, look here: https://r4ds.hadley.nz/iteration.html, https://adv-r.hadley.nz/functionals.html, https://r4ds.had.co.nz/many-models.html, https://www.tmwr.org.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "7 + 8 Automatisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/7_8_automatisation.html#exercises",
    "href": "DataManipulationVisualisation/7_8_automatisation.html#exercises",
    "title": "7 + 8 Automatisation",
    "section": "7.4 Exercises",
    "text": "7.4 Exercises\n\nRewrite the following code as a function:\n\nx / sum(x, na.rm = T)*100\ny / sum(y, na.rm = T)*100\nz / sum(z, na.rm = T)*100\n\nUse the function to calculate the percentage of each species in the penguins dataset.\nWrite your own function that takes a numeric vector of temperatures in Fahrenheit and returns them converted to Celsius using the formula \\(C = (F-32) *5/9\\). Test it with the following values: 0¬∞F, 20¬∞F, 68¬∞F, 86¬∞F, 100¬∞F.\n* Write a function that calculates the Shannon diversity index using the formula \\(H' = -‚àëp_i ln(p_i)\\). Use the function to calculate Shannon diversity of each plot in the sand vegetation dataset.\nTake the Pok√©mon dataset and visualise the distribution of defense power of water-type Pok√©mon. Turn this code into a function that helps you draw a histogram of defense power for different Pok√©mon types. * Try to generalize the code so that you can plot a distribution of any numerical variable.\nUse the function in a for loop and create plots of the distribution of defense power for all Pok√©mon types. * Save all plots in a plots folder.\n* Do the same using purrr functions.\n* Take the code for visualisation of Ellenberg-type indicator values in different forest types (Exercise 5 in Chapter 6) and turn it into a function. Draw the boxplots for four different Ellenberg-type indicator values using this function. Use a for loop or purrr functions to make these four plots. Combine them and save into the plots folder.",
    "crumbs": [
      "Data Manipulation and Visualization",
      "7 + 8 Automatisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/7_8_automatisation.html#further-reading",
    "href": "DataManipulationVisualisation/7_8_automatisation.html#further-reading",
    "title": "7 + 8 Automatisation",
    "section": "Further reading",
    "text": "Further reading\nR for Data Science: https://r4ds.hadley.nz/program.html\nHands on Programming with R: https://rstudio-education.github.io/hopr\nAdvanced R: https://adv-r.hadley.nz\nProgramming with dplyr: https://dplyr.tidyverse.org/articles/programming.html\nProgramming with tidyr: https://tidyr.tidyverse.org/articles/programming.html\nProgramming with ggplot2: https://ggplot2-book.org/programming.html\nTidy modeling with R: https://www.tmwr.org",
    "crumbs": [
      "Data Manipulation and Visualization",
      "7 + 8 Automatisation"
    ]
  },
  {
    "objectID": "DataManipulationVisualisation/data_manipulation_visualisation.html",
    "href": "DataManipulationVisualisation/data_manipulation_visualisation.html",
    "title": "Data Manipulation and Visualisation",
    "section": "",
    "text": "Osnova p≈ôedmƒõtu Manipulace a vizualizace dat\nV pr≈Øbƒõhu kurzu p≈ôedstav√≠me pokroƒçil√© metody manipulace a vizualizace dat v programu R, zejm√©na s vyu≈æit√≠m knihoven z kolekce tidyverse (tidyr, dplyr, tibble, purr, stringr, ggplot2, readr). C√≠lem p≈ôedmƒõtu je nauƒçit studenty rutinn√≠ manipulaci s daty, tak aby si je umƒõli importovat, upravit, filtrovat, p≈ôipojit nov√© informace z extern√≠ch dat, vytvo≈ôit nov√© promƒõnn√© (nap≈ô. na z√°kladƒõ v√Ωpoƒçtu), seskupit vzorky na z√°kladƒõ nƒõjak√© charakteristiky/informace a pro tyto skupiny vypoƒç√≠tat dal≈°√≠ parametry. D√°le se studenti nauƒç√≠ z√°kladn√≠ i pokroƒçil√© metody vizualizace dat pomoc√≠ ggplot2 a tvorbu z√°kladn√≠ch map v R. C√≠lem p≈ôedmƒõtu je i osvojen√≠ p≈ô√≠stupu open data science, kdy se nauƒç√≠ p≈ôipravit skript tak, aby bylo mo≈æn√© ho na z√°vƒõr publikovat na platformƒõ GitHub.\n\n\n1 √övod - 15. 9. 2025\n\nR jako programovac√≠ jazyk\nTidyverse package, %&gt;%, |&gt;\nprojekty v RStudiu, cheatsheets, keyboard shortcuts\n\nz√°sady tidy skriptu (√∫prava, nadpisy, z√°lo≈æky, pozn√°mky)\nzdroje informac√≠ a kde hledat pomoc, AI\nimport pomoc√≠ readr, readxl, na co si d√°vat pozor (encoding)\nstruktura dat (names, table, glimpse)\ntidy data (z√°sady, p≈ô√≠prava, kontrola), p≈ôejmenov√°n√≠ promƒõnn√Ωch (rename)\n\n\n\n2 Z√°kladn√≠ manipulace s daty - 22. 9. 2025\n\nz√°kladn√≠ manipulace s daty (select, filter, mutate, arrange, slice)\nexport dat (write_csv)\n\n\n\n3 Vizualizace dat pomoc√≠ ggplot - 29. 9. 2025\n\nlogika ggplot\nz√°kladn√≠ geom funkce (point, boxplot, histogram, barplot)\nprokl√°d√°n√≠ trend≈Ø\nsymboly, barvy\nlegenda, popisky os\ntheme\nulo≈æen√≠ grafu (ggsave)\n\n\n\n4 Wide vs.¬†long format - 13. 10. 2025\n\np≈ôevody form√°t≈Ø (pivot)\nnov√© promƒõnn√© (mutate, group_by, summarise)\nspecies richness, souƒçty/pod√≠ly r≈Øzn√Ωch hodnot v r√°mci vzorku (count)\n\n\n\n5 Join funkce - 20. 10. 2025\n\nspojovac√≠ funkce (left_join, full_join), p≈ôid√°n√≠ informac√≠ z jin√Ωch datov√Ωch soubor≈Ø\nfiltrovac√≠ funkce: semi_join, anti_join\npod√≠ly urƒçit√Ωch skupin podle vlastnost√≠, indikaƒçn√≠ hodnoty, CWM\n√∫prava nomenklatury (pokroƒçil√© mutate, summarise), sluƒçov√°n√≠ duplicit\nmutate s v√≠cen√°sobnou podm√≠nkou (ifelse, case_when)\n\n\n\n6 Pokroƒçil√° vizualizace dat - 27. 10. 2025\n\nggplot advanced - faceting, using multiple data sources, scales, position adjustments, legend modifications\nuseful extensions - patchwork, ggpubr, ggeffects\nshiny trailer (uk√°zka)\n\n\n\n7 + 8 Automatizace skriptu - 3. a 10. 11. 2025\n\nnaps√°n√≠ vlastn√≠ funkce\npou≈æit√≠ smyƒçek (for loops)\npurrr a uk√°zka pr√°ce s nested dataframes\n\n\n\n9 + 10 Mapy v R - 24. 11. a 1. 12. 2025\n\nmapy pomoc√≠ terra\nzobrazen√≠ vzork≈Ø v prostoru (p≈ôehledov√° mapa, mƒõ≈ô√≠tko, legenda‚Ä¶) na podkladƒõ open street maps\nkartogramy, mapov√°n√≠ v gridu\nextrakce dat z rastru, digit√°ln√≠ model\nv√Ωbƒõr dat pomoc√≠ masky\n≈°k√°lov√°n√≠ mapovan√Ωch bod≈Ø podle hodnot (barva, symbol)\n\n\n\n11 Od datab√°ze ke grafu (opakovac√≠ hodina) - 8. 12. 2025\n\nimport dat z datab√°ze, propojen√≠ r≈Øzn√Ωch datov√Ωch soubor≈Ø, √∫prava struktury dat\nfiltrov√°n√≠ podsouboru\nslouƒçen√≠ duplicit nap≈ô. vznikl√Ωch p≈ôevodem nomenklatury\nnapojen√≠ extern√≠ch vlastnost√≠, v√Ωpoƒçty v√°≈æen√Ωch pr≈Ømƒõr≈Ø\np≈ô√≠prava grafu pro publikaci\nslouƒçen√≠ cel√©ho procesu do jedn√© pipeliny\n\n\n\n12 GitHub - 15. 12. 2025\n\njak funguje, sta≈æen√≠ dat z ve≈ôejn√Ωch projekt≈Ø\nversion control\nvlastn√≠ √∫ƒçet, propojen√≠ s RStudiem\nvytvo≈ôen√≠ vlastn√≠ho √∫lo≈æi≈°tƒõ (repository), propojen√≠ s R projektem v poƒç√≠taƒçi\nspolupr√°ce na projektu (branch, commit, push, pull, merge conflicts)\npublikace skriptu, zve≈ôejnƒõn√≠ (doi, z√°sady readme)\nGitHub pages",
    "crumbs": [
      "Data Manipulation and Visualization"
    ]
  }
]