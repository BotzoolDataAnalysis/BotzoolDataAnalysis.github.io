
@article{campbell_should_2024,
	title = {Should we still teach or learn coding? {A} postgraduate student perspective on the use of large language models for coding in ecology and evolution},
	volume = {15},
	copyright = {© 2024 The Author(s). Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
	issn = {2041-210X},
	shorttitle = {Should we still teach or learn coding?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14396},
	doi = {10.1111/2041-210X.14396},
	abstract = {The extent to which coding skills are taught within ecology and evolution curricula remains largely unquantified. While coding, and especially R, proficiency is increasingly demanded in academic and professional contexts, many students encounter coding for the first time as postgraduates, presenting a steep learning curve alongside learning advanced statistics. With the emergence of large language models (LLMs), questions arise regarding the relevance of teaching coding when many of these tasks can now be automated. Here, we explore students' experiences with using LLMs for coding, highlighting both benefits and limitations. Through qualitative analysis of student perspectives, we identify several advantages of using LLMs for coding tasks, including enhanced search capabilities, provision of starting points and clear instructions, and troubleshooting support. However, limitations such as a lack of responsiveness to feedback and the prerequisite of extensive prior knowledge pose challenges to the effectiveness of student use of LLMs for coding at a beginner level. Concerns also arise regarding future access to LLMs, potentially exacerbating inequities in education. Despite the potential of LLMs, we argue for the continued importance of teaching coding skills alongside their integration with LLM support. Tutor-supported learning is essential for building foundational knowledge, facilitating comprehension of LLM outputs and fostering students' confidence in their abilities. Moreover, reliance solely on LLMs risks hindering deep learning and comprehension, thereby undermining the educational process. Our experiences underscore the significance of maintaining a balanced approach, leveraging LLMs as supplementary tools rather than substitutes for coding education in ecology and evolution courses.},
	language = {en},
	number = {10},
	urldate = {2025-09-16},
	journal = {Methods in Ecology and Evolution},
	author = {Campbell, Heather and Bluck, Thomas and Curry, Ella and Harris, Derrick and Pike, Billie and Wright, Bethany},
	year = {2024},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.14396},
	keywords = {artificial intelligence, ChatGPT, coding, education, large language models, teaching},
	pages = {1767--1770},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\HZHGXRKP\\Campbell et al. - 2024 - Should we still teach or learn coding A postgraduate student perspective on the use of large langua.pdf:application/pdf},
}

@inproceedings{chien_reducing_2023,
	address = {New York, NY, USA},
	series = {{HotCarbon} '23},
	title = {Reducing the carbon impact of generative {AI} inference (today and in 2035)},
	isbn = {979-8-4007-0242-6},
	url = {https://dl.acm.org/doi/10.1145/3604930.3605705},
	doi = {10.1145/3604930.3605705},
	abstract = {Generative AI, exemplified in ChatGPT, Dall-E 2, and Stable Diffusion, are exciting new applications consuming growing quantities of computing. We study the compute, energy, and carbon impacts of generative AI inference. Using ChatGPT as an exemplar, we create a workload model and compare request direction approaches (Local, Balance, CarbonMin), assessing their power use and carbon impacts.Our workload model shows that for ChatGPT-like services, inference dominates emissions, in one year producing 25x the carbon-emissions of training GPT-3. The workload model characterizes user experience, and experiments show that carbon emissions-aware algorithms (CarbonMin) can both maintain user experience and reduce carbon emissions dramatically (35\%). We also consider a future scenario (2035 workload and power grids), and show that CarbonMin can reduce emissions by 56\%. In both cases, the key is intelligent direction of requests to locations with low-carbon power. Combined with hardware technology advances, CarbonMin can keep emissions increase to only 20\% compared to 2022 levels for 55x greater workload. Finally we consider datacenter headroom to increase effectiveness of shifting. With headroom, CarbonMin reduces 2035 emissions by 71\%.},
	urldate = {2025-09-16},
	booktitle = {Proceedings of the 2nd {Workshop} on {Sustainable} {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Chien, Andrew A and Lin, Liuzixuan and Nguyen, Hai and Rao, Varsha and Sharma, Tristan and Wijayawardana, Rajini},
	year = {2023},
	pages = {1--7},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\HDB28R4K\\Chien et al. - 2023 - Reducing the Carbon Impact of Generative AI Inference (today and in 2035).pdf:application/pdf},
}

@article{cooper_harnessing_2024,
	title = {Harnessing large language models for coding, teaching and inclusion to empower research in ecology and evolution},
	volume = {15},
	copyright = {© 2024 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14325},
	doi = {10.1111/2041-210X.14325},
	abstract = {Large language models (LLMs) are a type of artificial intelligence (AI) that can perform various natural language processing tasks. The adoption of LLMs has become increasingly prominent in scientific writing and analyses because of the availability of free applications such as ChatGPT. This increased use of LLMs not only raises concerns about academic integrity but also presents opportunities for the research community. Here we focus on the opportunities for using LLMs for coding in ecology and evolution. We discuss how LLMs can be used to generate, explain, comment, translate, debug, optimise and test code. We also highlight the importance of writing effective prompts and carefully evaluating the outputs of LLMs. In addition, we draft a possible road map for using such models inclusively and with integrity. LLMs can accelerate the coding process, especially for unfamiliar tasks, and free up time for higher level tasks and creative thinking while increasing efficiency and creative output. LLMs also enhance inclusion by accommodating individuals without coding skills, with limited access to education in coding, or for whom English is not their primary written or spoken language. However, code generated by LLMs is of variable quality and has issues related to mathematics, logic, non-reproducibility and intellectual property; it can also include mistakes and approximations, especially in novel methods. We highlight the benefits of using LLMs to teach and learn coding, and advocate for guiding students in the appropriate use of AI tools for coding. Despite the ability to assign many coding tasks to LLMs, we also reaffirm the continued importance of teaching coding skills for interpreting LLM-generated code and to develop critical thinking skills. As editors of MEE, we support—to a limited extent—the transparent, accountable and acknowledged use of LLMs and other AI tools in publications. If LLMs or comparable AI tools (excluding commonly used aids like spell-checkers, Grammarly and Writefull) are used to produce the work described in a manuscript, there must be a clear statement to that effect in its Methods section, and the corresponding or senior author must take responsibility for any code (or text) generated by the AI platform.},
	language = {en},
	number = {10},
	urldate = {2025-09-16},
	journal = {Methods in Ecology and Evolution},
	author = {Cooper, Natalie and Clark, Adam T. and Lecomte, Nicolas and Qiao, Huijie and Ellison, Aaron M.},
	year = {2024},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.14325},
	keywords = {artificial intelligence, ChatGPT, coding, large language models, teaching, inclusion},
	pages = {1757--1763},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\LN7EBN3L\\Cooper et al. - 2024 - Harnessing large language models for coding, teaching and inclusion to empower research in ecology a.pdf:application/pdf},
}

@misc{francoisn_-_fbriatteorg_ai-generated_2025,
	title = {{AI}-generated code comes with security risks {\textbar} {R}-bloggers},
	url = {https://www.r-bloggers.com/2025/04/ai-generated-code-comes-with-security-risks/},
	abstract = {More and more students are using AI-generated code in their studies, without necessarily understanding the security risks that this entails. This has consequences for users such as students learning how to code in R. How AI-generated code happens Gen...},
	language = {en-US},
	urldate = {2025-09-16},
	author = {Françoisn - f@briatte.org},
	month = apr,
	year = {2025},
}

@article{johnson_pressure_2024,
	title = {Pressure to publish introduces large-language model risks},
	volume = {15},
	copyright = {© 2024 The Author(s). Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14397},
	doi = {10.1111/2041-210X.14397},
	abstract = {Large-language models (LLMs) have the potential to accelerate research in ecology and evolution, cultivating new insights and innovation. However, whilst revelling in the plethora of opportunities, researchers need to consider that LLM use could also introduce risks. An important piece of context underpinning this perspective is the pressure to publish, where research careers are defined, at least partly, by publication metrics like number of papers, impact factor, citations etc. Coupled with academic employment insecurity, especially during early career, researchers may reason that LLMs are a low-risk and high-reward tool for publication. However, this pressure to publish can introduce risks if LLMs are used as a shortcut to game publication metrics instead of a tool to support true innovation. These risks may ultimately reduce research quality, stifle researcher development and incur reputational damage for researchers and the entire scientific record. We conclude with a series of recommendations to mitigate the magnitude of these risks and encourage researchers to apply caution whilst maximising LLM potential.},
	language = {en},
	number = {10},
	urldate = {2025-09-16},
	journal = {Methods in Ecology and Evolution},
	author = {Johnson, Thomas F. and Simmons, Benno I. and Millard, Joseph and Strydom, Tanya and Danet, Alain and Sweeny, Amy R. and Evans, Luke C.},
	year = {2024},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.14397},
	keywords = {ecology, evolution, large-language models, paper hacking, publish or perish},
	pages = {1771--1773},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\2FQPBC92\\Johnson et al. - 2024 - Pressure to publish introduces large-language model risks.pdf:application/pdf},
}

@misc{kokotajlo_ai_2025,
	title = {{AI} 2027},
	url = {https://ai-2027.com/race#narrative-2025-08-31},
	urldate = {2025-09-16},
	author = {Kokotajlo, D and Alexander, S and Larsen, Th. and Lifland, E and Dean, R},
	year = {2025},
}

@article{mammides_role_2024,
	title = {The role of large language models in interdisciplinary research: {Opportunities}, challenges and ways forward},
	volume = {15},
	copyright = {© 2024 The Author(s). Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
	issn = {2041-210X},
	shorttitle = {The role of large language models in interdisciplinary research},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14398},
	doi = {10.1111/2041-210X.14398},
	abstract = {Large language models (LLMs) are gaining importance in research as they offer many benefits. One often overlooked benefit is their potential to facilitate and support interdisciplinary research, which is key to addressing current global challenges, such as the twin crises of biodiversity loss and climate change. LLMs can help reduce the costs associated with knowledge transfer and bridge gaps between different fields of study. They can also be especially useful in helping ecologists understand and adopt powerful techniques common in other fields. However, using LLMs in research, especially for complex tasks, carries important risks, including the possibility of generating inaccurate information, which can lead to false conclusions. We recommend that researchers adhere to best practices when using LLMs for research by providing appropriate prompts and dividing complex tasks into smaller, more manageable tasks that facilitate learning and testing. Moreover, journals should implement policies to ensure that information and code generated using LLMs are properly validated. Academic programs should incorporate formal training in LLMs, equipping students and researchers with the necessary skills to use these tools more effectively and responsibly, including for interdisciplinary research.},
	language = {en},
	number = {10},
	urldate = {2025-09-16},
	journal = {Methods in Ecology and Evolution},
	author = {Mammides, Christos and Papadopoulos, Harris},
	year = {2024},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.14398},
	keywords = {ChatGPT, large language models, ecological research, Gemini, generative artificial intelligence, machine learning},
	pages = {1774--1776},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\7SRXVPLT\\Mammides and Papadopoulos - 2024 - The role of large language models in interdisciplinary research Opportunities, challenges and ways.pdf:application/pdf},
}

@article{millard_chatgpt_2024,
	title = {{ChatGPT} is likely reducing opportunity for support, friendship and learned kindness in research},
	volume = {15},
	copyright = {© 2024 The Author(s). Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14395},
	doi = {10.1111/2041-210X.14395},
	abstract = {Large language models (LLM) have proved to be highly popular since the release of ChatGPT, leading many researchers to explore their potential across multiple fields of scientific research. In a recent Perspective, Cooper et al. (2024) highlight a set of benefits and challenges for the use of LLMs in ecology, emphasising their value to coding in research and education. While we agree that the ability of LLMs to assist in the coding process is remarkable, researchers should be conscious that this capability is likely changing the lived experience of primarily computational researchers, especially early career ecologists between Masters and Postdoctoral career stages. In particular, since the release of ChatGPT, the authors of this paper have noticed a marked reduction in the frequency of social interactions emergent from coding and statistics queries. These questions are highly likely still being asked, but now often exclusively to a LLM. Further research is needed to fully understand the effect of LLMs on the lived-experience of researchers and students. For primarily computational researchers, ChatGPT is likely reducing emergent opportunity for support, friendship and learned kindness. Group leaders should recognise this and foster deliberate within-group communication and collaboration.},
	language = {en},
	number = {10},
	urldate = {2025-09-16},
	journal = {Methods in Ecology and Evolution},
	author = {Millard, Joseph and Christie, Alec P. and Dicks, Lynn V. and Isip, Justin E. and Johnson, Thomas F. and Skinner, Grace and Spake, Rebecca},
	year = {2024},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.14395},
	keywords = {ecology, ChatGPT, computational research, large language models (LLMs), mental health, pastoral support},
	pages = {1764--1766},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\IY2QCKQC\\Millard et al. - 2024 - ChatGPT is likely reducing opportunity for support, friendship and learned kindness in research.pdf:application/pdf},
}

@misc{rstudiodatalab_how_2023,
	title = {How to use {ChatGPT} for data analysis in {R}},
	url = {https://rstudiodatalab.medium.com/how-to-use-chatgpt-for-data-analysis-in-r-891372af842},
	abstract = {Key points},
	language = {en},
	urldate = {2025-09-16},
	journal = {Medium},
	author = {RStudioDataLab},
	month = aug,
	year = {2023},
}

@inproceedings{strubell_energy_2019,
	address = {Florence, Italy},
	title = {Energy and policy considerations for deep learning in {NLP}},
	url = {https://doi.org/10.18653/v1/P19-1355},
	doi = {10.18653/v1/P19-1355},
	abstract = {Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.},
	urldate = {2025-09-16},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
	editor = {Korhonen, Anna and Traum, David and Màrquez, Lluís},
	month = jun,
	year = {2019},
	pages = {3645--3650},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\68BLW7G7\\Strubell et al. - 2019 - Energy and Policy Considerations for Deep Learning in NLP.pdf:application/pdf},
}

@misc{the_group_for_ai_in_teaching_at_masaryk_university_statement_2023,
	title = {Statement on the application of artificial intelligence in teaching at {Masaryk} {University}},
	url = {https://www.muni.cz/en/about-us/official-notice-board/statement-on-the-application-of-ai},
	language = {en},
	urldate = {2025-09-16},
	journal = {Masaryk University},
	author = {The group for AI in teaching at Masaryk University},
	year = {2023},
}

@article{wu_unveiling_2024,
	title = {Unveiling security, privacy, and ethical concerns of {ChatGPT}},
	volume = {2},
	issn = {2949-7159},
	url = {https://www.sciencedirect.com/science/article/pii/S2949715923000707},
	doi = {10.1016/j.jiixd.2023.10.007},
	abstract = {This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.},
	number = {2},
	urldate = {2025-09-16},
	journal = {Journal of Information and Intelligence},
	author = {Wu, Xiaodong and Duan, Ran and Ni, Jianbing},
	month = mar,
	year = {2024},
	keywords = {ChatGPT, Ethics, Large language model (LLM), Privacy, Security},
	pages = {102--115},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\6KDF2CIH\\Wu et al. - 2024 - Unveiling security, privacy, and ethical concerns of ChatGPT.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\klara\\Zotero\\storage\\Z9W922WW\\S2949715923000707.html:text/html},
}

@article{lau_artificial_2025,
	title = {Artificial intelligence-based psychotherapeutic intervention on psychological outcomes: {A} meta-analysis and meta-regression},
	volume = {2025},
	copyright = {Copyright © 2025 Ying Lau et al. Depression and Anxiety published by John Wiley \& Sons Ltd.},
	issn = {1520-6394},
	shorttitle = {Artificial {Intelligence}–{Based} {Psychotherapeutic} {Intervention} on {Psychological} {Outcomes}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/da/8930012},
	doi = {10.1155/da/8930012},
	abstract = {Background: Artificial intelligence (AI)–based psychotherapeutic interventions may bring a new and viable approach to expanding psychiatric care. However, evidence of their effectiveness remains scarce. We evaluated the efficacy of AI-based psychotherapeutic interventions on depressive, anxiety, and stress symptoms at postintervention and follow-up assessments. Methods: A three-step comprehensive search via nine electronic databases (PubMed, Embase, CINAHL, Cochrane Library, Scopus, IEEE Xplore, Web of Science, PsycINFO, and ProQuest Dissertations and Theses) was performed. Results: Thirty randomized controlled trials (RCTs) in 31 publications involving 6100 participants from nine countries were included. The majority (79.1\%) of trials with intention-to-treat analysis but less than half (48.6\%) of trials with perprotocol analysis were graded as low risk. Meta-analyses showed that interventions significantly reduced depressive symptoms at the postintervention assessment (t = −4.40, p = 0.001) with medium effect size (g = −0.54, 95\% CI: −0.79 to −0.29) and at 6–12 months of assessment (t = −3.14, p {\textless} 0.016) with small effect size (g = −0.23, 95\% CI: −0.40 to −0.06) in comparison with comparators. Our subgroup analyses revealed that the depressed participants had a significantly larger effect size in reducing depressive symptoms than participants with stress and other conditions. At postintervention and follow-up assessments, we discovered that AI-based psychotherapeutic interventions did not significantly alter anxiety, stress, and the total scores of depressive, anxiety, and stress symptoms in comparison to comparators. The random-effects univariate meta-regression did not identify any significant covariates for depressive and anxiety symptoms at postintervention. The certainty of evidence ranged between moderate and very low. Conclusions: AI-based psychotherapeutic interventions can be used in addition to usual treatments for reducing depressive symptoms. Well-designed RCTs with long-term follow-up data are warranted. Trial Registration: CRD42022330228},
	language = {en},
	number = {1},
	urldate = {2025-09-16},
	journal = {Depression and Anxiety},
	author = {Lau, Ying and Ang, Wei How Darryl and Ang, Wen Wei and Pang, Patrick Cheong-Iao and Wong, Sai Ho and Chan, Kin Sun},
	year = {2025},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1155/da/8930012},
	keywords = {meta-analysis, artificial intelligence–based psychotherapeutic intervention, meta-regression, psychological outcome},
	pages = {8930012},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\DSSM8CY5\\Lau et al. - 2025 - Artificial Intelligence–Based Psychotherapeutic Intervention on Psychological Outcomes A Meta-Analy.pdf:application/pdf},
}

@misc{stanford_cs324_introduction_2022,
	title = {Introduction},
	url = {https://stanford-cs324.github.io/winter2022/lectures/introduction/},
	abstract = {Understanding and developing large language models.},
	language = {en-US},
	urldate = {2025-09-16},
	journal = {CS324},
	author = {Stanford CS324},
	year = {2022},
	file = {Snapshot:C\:\\Users\\klara\\Zotero\\storage\\Y4J4ZVJV\\introduction.html:text/html},
}

@article{wolfram_what_2023,
	title = {What is {ChatGPT} doing … and why does {It} work?},
	url = {https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/},
	abstract = {Stephen Wolfram explores the broader picture of what's going on inside ChatGPT and why it produces meaningful text. Discusses models, training neural nets, embeddings, tokens, transformers, language syntax.},
	language = {en},
	urldate = {2025-09-16},
	journal = {Stephen Wolfram Writings},
	author = {Wolfram, Stephen},
	month = feb,
	year = {2023},
}

@misc{ellen_how_2025,
	title = {How would {I} learn to code with {ChatGPT} if {I} had to start again},
	url = {https://towardsdatascience.com/how-would-i-learn-to-code-with-chatgpt-if-i-had-to-start-again/},
	abstract = {Exploring ChatGPT in my 15 years coding learning journey — Moving beyond copy-pasting},
	language = {en-US},
	urldate = {2025-09-16},
	journal = {Towards Data Science},
	author = {Ellen, Livia},
	month = may,
	year = {2025},
	file = {Snapshot:C\:\\Users\\klara\\Zotero\\storage\\7668EFTB\\how-would-i-learn-to-code-with-chatgpt-if-i-had-to-start-again.html:text/html},
}

@misc{vieira_ai_2025,
	title = {{AI} code guide},
	url = {https://github.com/automata/aicodeguide},
	abstract = {AI Code Guide is a roadmap to start coding with AI},
	urldate = {2025-09-16},
	author = {Vieira, Vilson and Raymond, Eric S.},
	month = sep,
	year = {2025},
	note = {original-date: 2025-04-08T14:53:26Z},
	keywords = {ai, aicode, aicoding, course, llm, roadmap, vibe-coding},
}

@misc{willison_hallucinations_2025,
	title = {Hallucinations in code are the least dangerous form of {LLM} mistakes},
	url = {https://simonwillison.net/2025/Mar/2/hallucinations-in-code/},
	abstract = {A surprisingly common complaint I see from developers who have tried using LLMs for code is that they encountered a hallucination—usually the LLM inventing a method or even a full …},
	language = {en-gb},
	urldate = {2025-09-16},
	journal = {Simon Willison’s Weblog},
	author = {Willison, Simon},
	year = {2025},
	file = {Snapshot:C\:\\Users\\klara\\Zotero\\storage\\B6GXSHPF\\hallucinations-in-code.html:text/html},
}

@misc{cetinkaya-rundel_learning_2025,
	title = {Learning the tidyverse with the help of {AI} tools},
	url = {https://www.tidyverse.org/blog/2025/04/learn-tidyverse-ai/},
	abstract = {Tips and recommendations for learning the tidyverse with AI tools.},
	language = {en-us},
	urldate = {2025-09-16},
	author = {Çetinkaya-Rundel, M},
	year = {2025},
}

@misc{davjekar_ai-assisted_2024,
	title = {{AI}-assisted software development: {A} comprehensive guide with practical prompts ({Part} 1/3)},
	url = {https://aalapdavjekar.medium.com/ai-assisted-software-development-a-comprehensive-guide-with-practical-prompts-part-1-3-989a529908e0},
	urldate = {2025-09-16},
	author = {Davjekar, A},
	year = {2024},
}

@article{lubiana_ten_2023,
	title = {Ten quick tips for harnessing the power of {ChatGPT} in computational biology},
	volume = {19},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011319},
	doi = {10.1371/journal.pcbi.1011319},
	language = {en},
	number = {8},
	urldate = {2025-09-16},
	journal = {PLOS Computational Biology},
	author = {Lubiana, Tiago and Lopes, Rafael and Medeiros, Pedro and Silva, Juan Carlo and Goncalves, Andre Nicolau Aquime and Maracaja-Coutinho, Vinicius and Nakaya, Helder I.},
	year = {2023},
	note = {Publisher: Public Library of Science},
	keywords = {Bioinformatics, Biologists, Computational biology, Language, Programming languages, Scientists, Syntax, Verbal communication},
	pages = {e1011319},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\V9HVR5QG\\Lubiana et al. - 2023 - Ten quick tips for harnessing the power of ChatGPT in computational biology.pdf:application/pdf},
}

@misc{willison_heres_2025,
	title = {Here’s how {I} use {LLMs} to help me write code},
	url = {https://simonwillison.net/2025/Mar/11/using-llms-for-code/},
	abstract = {Online discussions about using Large Language Models to help write code inevitably produce comments from developers who’s experiences have been disappointing. They often ask what they’re doing wrong—how come some …},
	language = {en-gb},
	urldate = {2025-09-16},
	journal = {Simon Willison’s Weblog},
	author = {Willison, Simon},
	year = {2025},
	file = {Snapshot:C\:\\Users\\klara\\Zotero\\storage\\YPDRJTUE\\using-llms-for-code.html:text/html},
}

@inproceedings{brown_language_2020,
	title = {Language models are few-shot learners},
	volume = {33},
	url = {https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
	abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	urldate = {2025-09-16},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year = {2020},
	pages = {1877--1901},
	file = {Full Text PDF:C\:\\Users\\klara\\Zotero\\storage\\4C9JUUL6\\Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf},
}
